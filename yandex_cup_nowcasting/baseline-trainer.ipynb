{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1c2871d15b784ebd9a991737386418b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cdba8eded7a4b13bf287ed78b6ccf94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fa845a0f3204027b8741e11993ddd9d","max":2136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e685f357677142f6adef43099a08ef6b","value":1700}},"678b9f44e2f048e189c7fa0b7adcdaef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"7341382e5ecb4fdfb92374da09c41e1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bd7f3989b6eb44738c17e41fbb9f6ccd","IPY_MODEL_5cdba8eded7a4b13bf287ed78b6ccf94","IPY_MODEL_93d9331ab86f4f029e8268bea1b23378"],"layout":"IPY_MODEL_678b9f44e2f048e189c7fa0b7adcdaef"}},"7fa845a0f3204027b8741e11993ddd9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89ecb09033404331a1945b0d698a74aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93d9331ab86f4f029e8268bea1b23378":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89ecb09033404331a1945b0d698a74aa","placeholder":"​","style":"IPY_MODEL_c46ee2e33f724b26a65fe8f59b927c26","value":" 1700/2136 [1:03:44&lt;16:20,  0.44it/s, v_num=1]"}},"bd7f3989b6eb44738c17e41fbb9f6ccd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c2871d15b784ebd9a991737386418b7","placeholder":"​","style":"IPY_MODEL_cf64f8bda6eb4c16a3fd25c9df1c4914","value":"Epoch 0:  80%"}},"c46ee2e33f724b26a65fe8f59b927c26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf64f8bda6eb4c16a3fd25c9df1c4914":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e685f357677142f6adef43099a08ef6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df2c3481b2dd439f95002212b6a812d1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c7f1517f46341c591e8730ede2d52a6","IPY_MODEL_080b51a28841421baec3587bd4bb5d0d","IPY_MODEL_c1a2dcf8744245289e7ee91af7155f4e"],"layout":"IPY_MODEL_29dea130b1cd46edb075a8fb8a9e067c"}},"8c7f1517f46341c591e8730ede2d52a6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f121232b8bfb490f8468944d72cb870b","placeholder":"​","style":"IPY_MODEL_e9658302d6b24722977891ec8c3f9918","value":"Epoch 0: 100%"}},"080b51a28841421baec3587bd4bb5d0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02df16e03ea24e95894ba212575a6aa2","max":2137,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8918f6ef72054d36bf9dd2d6fde5f87d","value":2137}},"c1a2dcf8744245289e7ee91af7155f4e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdc78e41487b46a0be1c68eecce1d5f7","placeholder":"​","style":"IPY_MODEL_205f95e62ec24e5da5f75b7b91a25b55","value":" 2137/2137 [32:51&lt;00:00,  1.08it/s, v_num=0]"}},"29dea130b1cd46edb075a8fb8a9e067c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"f121232b8bfb490f8468944d72cb870b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9658302d6b24722977891ec8c3f9918":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02df16e03ea24e95894ba212575a6aa2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8918f6ef72054d36bf9dd2d6fde5f87d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdc78e41487b46a0be1c68eecce1d5f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"205f95e62ec24e5da5f75b7b91a25b55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c2b6efebbb5454e98fb596de85d4aab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_decd17c37d1c4008ad7e25736291a741","IPY_MODEL_575a8d8837064bc39e530f6f92f72a98","IPY_MODEL_ddf0e3d6dd0c473787c9da84b4aa812f"],"layout":"IPY_MODEL_2a2378586a684f328359596471386c4c"}},"decd17c37d1c4008ad7e25736291a741":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ade6137503de4500a7fad90fc197bf78","placeholder":"​","style":"IPY_MODEL_815cb215b6334689a153203664270b1e","value":"Epoch 0: 100%"}},"575a8d8837064bc39e530f6f92f72a98":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ab2f919c96c4e67b7fd22ab024d8c77","max":2137,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d2addea19f8c441496fe0e37742ff010","value":2137}},"ddf0e3d6dd0c473787c9da84b4aa812f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8d2e4595b59491dbfe71f43c1f584fe","placeholder":"​","style":"IPY_MODEL_1ccba0e73382487f9577e7a4d1b3a481","value":" 2137/2137 [32:59&lt;00:00,  1.08it/s, v_num=1]"}},"2a2378586a684f328359596471386c4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ade6137503de4500a7fad90fc197bf78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"815cb215b6334689a153203664270b1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ab2f919c96c4e67b7fd22ab024d8c77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2addea19f8c441496fe0e37742ff010":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8d2e4595b59491dbfe71f43c1f584fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ccba0e73382487f9577e7a4d1b3a481":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a717014939ba49c9a0715362dd8309bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c1cd253a40e491b81178d46c82a5d11","IPY_MODEL_61eb63c1dd6a4cf8824ecc5eb91c3d08","IPY_MODEL_3f4b82f09b0946388a0ba73022d71091"],"layout":"IPY_MODEL_5c8d4bc596b146e3abdea6cc696c99a6"}},"4c1cd253a40e491b81178d46c82a5d11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff3922456ea440ffbf64c79a552ea72c","placeholder":"​","style":"IPY_MODEL_09cbea143f3b48549154ca2f968cbc70","value":"Epoch 0:  96%"}},"61eb63c1dd6a4cf8824ecc5eb91c3d08":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c086102011d494696cd8b463c602c8b","max":2136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_48631a28bd8c49b99fae65fe41075053","value":2060}},"3f4b82f09b0946388a0ba73022d71091":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a150466f924d4bedad3c04980dd3927d","placeholder":"​","style":"IPY_MODEL_1ebe51a5d7be4cd1bb5847ce63f7e5c4","value":" 2060/2136 [31:51&lt;01:10,  1.08it/s, v_num=2]"}},"5c8d4bc596b146e3abdea6cc696c99a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"ff3922456ea440ffbf64c79a552ea72c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09cbea143f3b48549154ca2f968cbc70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c086102011d494696cd8b463c602c8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48631a28bd8c49b99fae65fe41075053":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a150466f924d4bedad3c04980dd3927d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ebe51a5d7be4cd1bb5847ce63f7e5c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6877002,"sourceType":"datasetVersion","datasetId":3951530},{"sourceId":6950106,"sourceType":"datasetVersion","datasetId":3991623}],"dockerImageVersionId":30559,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zKXs-RluegKv","outputId":"9d6630d4-038b-4a8a-cc20-eb2df113f9eb","execution":{"iopub.status.busy":"2023-11-12T11:34:29.939925Z","iopub.execute_input":"2023-11-12T11:34:29.940314Z","iopub.status.idle":"2023-11-12T11:35:01.787956Z","shell.execute_reply.started":"2023-11-12T11:34:29.940280Z","shell.execute_reply":"2023-11-12T11:35:01.786924Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.0.8)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.23.5)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.0.0)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.1)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0)\nRequirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2023.9.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.1.1)\nRequirement already satisfied: packaging>=17.1 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.6.3)\nRequirement already satisfied: lightning-utilities>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.1->pytorch-lightning) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"PATH = '/kaggle/input/nowcasting-yandex-cup/'","metadata":{"id":"qlcnSNjHgJjG","execution":{"iopub.status.busy":"2023-11-12T11:35:01.790077Z","iopub.execute_input":"2023-11-12T11:35:01.790394Z","iopub.status.idle":"2023-11-12T11:35:01.794920Z","shell.execute_reply.started":"2023-11-12T11:35:01.790366Z","shell.execute_reply":"2023-11-12T11:35:01.794005Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport tqdm\nimport pytorch_lightning as L","metadata":{"id":"PVn7YOgXeyd3","execution":{"iopub.status.busy":"2023-11-12T11:35:01.796242Z","iopub.execute_input":"2023-11-12T11:35:01.796616Z","iopub.status.idle":"2023-11-12T11:35:07.243632Z","shell.execute_reply.started":"2023-11-12T11:35:01.796584Z","shell.execute_reply":"2023-11-12T11:35:07.242814Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ROk7rQUgxV90","outputId":"3c5cdc79-c1d2-4859-a21c-54bc2272c0b8","execution":{"iopub.status.busy":"2023-11-12T11:35:07.245598Z","iopub.execute_input":"2023-11-12T11:35:07.245892Z","iopub.status.idle":"2023-11-12T11:35:07.277260Z","shell.execute_reply.started":"2023-11-12T11:35:07.245866Z","shell.execute_reply":"2023-11-12T11:35:07.276289Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"cell_type":"code","source":"from pytorch_lightning import seed_everything\nimport random\nseed=7\nseed_everything(seed, workers=True)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3j7U282IC14","outputId":"f57ee465-9152-4dd3-afa0-4b6c47e105eb","execution":{"iopub.status.busy":"2023-11-12T11:35:07.278765Z","iopub.execute_input":"2023-11-12T11:35:07.279432Z","iopub.status.idle":"2023-11-12T11:35:07.289285Z","shell.execute_reply.started":"2023-11-12T11:35:07.279395Z","shell.execute_reply":"2023-11-12T11:35:07.288532Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class RadarDataset(data.Dataset):\n\n    def __init__(self, list_of_files, in_seq_len=4, out_seq_len=12, mode='sequentially', rotate = 0, with_time=False):\n        self.in_seq_len = in_seq_len\n        self.out_seq_len = out_seq_len\n        self.seq_len = in_seq_len + out_seq_len\n        self.with_time = with_time\n        self.__prepare_timestamps_mapping(list_of_files)\n        self.__prepare_sequences(mode)\n        self.rotate = rotate\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, index):\n        to_append = []\n        data = []\n        targets = []\n        for timestamp in self.sequences[index]:\n            with h5py.File(self.timestamp_to_file[timestamp]) as d:\n                targets.append(np.array(torch.rot90(torch.tensor(np.array([d[timestamp]['intensity']])), self.rotate)))\n                data.append(np.array([d[timestamp]['intensity'], d[timestamp]['reflectivity'][0], d[timestamp]['reflectivity'][1], d[timestamp]['reflectivity'][2], \n                                      d[timestamp]['reflectivity'][3], d[timestamp]['reflectivity'][4], d[timestamp]['reflectivity'][5],\n                                     d[timestamp]['reflectivity'][6], d[timestamp]['reflectivity'][7],\n                                     d[timestamp]['radial_velocity'][0], d[timestamp]['radial_velocity'][1], d[timestamp]['radial_velocity'][2],\n                                     d[timestamp]['radial_velocity'][3], d[timestamp]['radial_velocity'][4],\n                                     d[timestamp]['radial_velocity'][5], d[timestamp]['radial_velocity'][6], d[timestamp]['radial_velocity'][7]]))\n                #data.append(np.array([d[timestamp]['intensity'], d[timestamp]['events'], d[timestamp]['reflectivity'][0]]))\n                \n        data = np.array(data)\n        targets = np.array(targets)\n        #data = np.expand_dims(data, axis=1)\n        #targets = np.expand_dims(targets, axis=1)\n        data[data == -1e6] = 0\n        data[data == -2e6] = -1\n        targets[targets == -1e6] = 0\n        targets[targets == -2e6] = -1\n        inputs = data[:self.in_seq_len]\n        targets = targets[self.in_seq_len:]\n        if self.with_time:\n            return (inputs, self.sequences[index][-1]), targets\n        else:\n            return inputs, targets\n\n    def __prepare_timestamps_mapping(self, list_of_files):\n        self.timestamp_to_file = {}\n        for filename in list_of_files:\n            with h5py.File(filename) as d:\n                self.timestamp_to_file = {\n                    **self.timestamp_to_file,\n                    **dict(map(lambda x: (x, filename), d.keys()))\n                }\n\n    def __prepare_sequences(self, mode):\n        timestamps = np.unique(sorted(self.timestamp_to_file.keys()))\n        if mode == 'sequentially':\n            self.sequences = [\n                timestamps[index * self.seq_len: (index + 1) * self.seq_len]\n                for index in range(len(timestamps) // self.seq_len)\n            ]\n        elif mode == 'overlap':\n            self.sequences = [\n                timestamps[index: index + self.seq_len]\n                for index in range(len(timestamps) - self.seq_len + 1)\n            ] \n        else:\n            raise Exception(f'Unknown mode {mode}')\n        self.sequences = list(filter(\n            lambda x: int(x[-1]) - int(x[0]) == (self.seq_len - 1) * 600,\n            self.sequences\n        ))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-12T11:35:07.307381Z","iopub.execute_input":"2023-11-12T11:35:07.307665Z","iopub.status.idle":"2023-11-12T11:35:07.328396Z","shell.execute_reply.started":"2023-11-12T11:35:07.307641Z","shell.execute_reply":"2023-11-12T11:35:07.327497Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ConvLSTMCell(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n\n        if activation == 'tanh':\n            self.activation = torch.tanh\n        elif activation == 'relu':\n            self.activation = torch.relu\n\n        self.conv_int_0 = nn.Conv2d(\n            in_channels=in_channels + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        \n        self.conv_int_1 = nn.Conv2d(\n            in_channels= 4 * out_channels,\n            out_channels=4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        self.conv_refl_0 = nn.Conv2d(\n            in_channels=16 + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        \n    def forward(self, X, H_prev, C_prev):\n        \n        int_X = X[:,0:1, :, :]\n        refl_X= X[:,1:, :, :]\n        H_prev_int, H_prev_refl = torch.chunk(H_prev, chunks=2, dim=1)\n        conv_int_output = self.conv_int_1(self.activation(self.conv_int_0(torch.cat([int_X, H_prev_int], dim=1))))\n        conv_refl_output = self.conv_refl_0(torch.cat([refl_X, H_prev_refl], dim=1))\n        \n        i_conv_int, f_conv_int, C_conv_int, o_conv_int = torch.chunk(conv_int_output, chunks=4, dim=1)\n        i_conv_refl, f_conv_refl, C_conv_refl, o_conv_refl = torch.chunk(conv_refl_output, chunks=4, dim=1)\n\n\n        input_gate = torch.sigmoid(torch.cat([i_conv_int, i_conv_refl], dim=1))\n        forget_gate = torch.sigmoid(torch.cat([f_conv_int, f_conv_refl], dim=1))\n        output_gate = torch.sigmoid(torch.cat([o_conv_int, o_conv_refl], dim=1))\n        C_conv = torch.cat([C_conv_int, C_conv_refl], dim=1)\n        C = forget_gate * C_prev + input_gate * self.activation(C_conv)\n        H = output_gate * self.activation(C)\n        return H, C\n\n\nclass ConvLSTM(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n        self.out_channels = out_channels\n        self.convLSTMCell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding, activation)\n\n    def forward(self, X):\n        batch_size, seq_len, _, height, width = X.size()\n        output = torch.zeros(batch_size, seq_len, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        H = torch.zeros(batch_size, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        C = torch.zeros(batch_size, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        for time_step in range(seq_len):\n            H, C = self.convLSTMCell(X[:, time_step], H, C)\n            output[:, time_step] = H\n        return output\n\n\nclass Seq2Seq(nn.Module):\n\n    def __init__(\n        self, num_channels, num_kernels, kernel_size, padding, activation, num_layers, out_seq_len\n    ):\n        super().__init__()\n        self.out_seq_len = out_seq_len\n\n        self.activation = torch.relu\n        self.sequential = nn.Sequential()\n        self.sequential.add_module(\n            'convlstm1',\n            ConvLSTM(\n                in_channels=num_channels,\n                out_channels=num_kernels,\n                kernel_size=kernel_size,\n                padding=padding,\n                activation=activation\n            )\n        )\n        for layer_index in range(2, num_layers + 1):\n            self.sequential.add_module(\n                f'convlstm{layer_index}',\n                ConvLSTM(\n                    in_channels=num_kernels,\n                    out_channels=num_kernels,\n                    kernel_size=kernel_size,\n                    padding=padding,\n                    activation=activation\n                )\n            )\n        self.conv = nn.Conv2d(\n            in_channels=2 * num_kernels,\n            out_channels=num_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n\n    def forward(self, X):\n        batch_size, seq_len, num_channels, height, width = X.size()\n        inputs = torch.zeros(\n            batch_size, seq_len + self.out_seq_len - 1, num_channels, height, width,\n            device=self.conv.weight.device\n        )\n        inputs[:, :seq_len] = X\n        output = self.sequential(inputs)\n        output = torch.stack([\n            self.conv(output[:, index + seq_len - 1])\n            for index in range(self.out_seq_len)\n        ], dim=1)\n        return output\n\n\nclass ConvLSTMModel(L.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.model = Seq2Seq(\n            num_channels=1,\n            num_kernels=32,\n            kernel_size=(3, 3),\n            padding=(1, 1),\n            activation='relu',\n            num_layers=1,\n            out_seq_len=12\n        )\n\n    def forward(self, x):\n        x = x.to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        output = self.model(x)\n        return output\n\n    def training_step(self, batch):\n        x, y = batch\n        out = self.forward(x)\n        out[y == -1] = -1\n        loss = F.mse_loss(out, y)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)\n        return optimizer","metadata":{"id":"kEkQxBPVcuX2","execution":{"iopub.status.busy":"2023-11-12T11:35:07.330045Z","iopub.execute_input":"2023-11-12T11:35:07.330363Z","iopub.status.idle":"2023-11-12T11:35:07.357878Z","shell.execute_reply.started":"2023-11-12T11:35:07.330327Z","shell.execute_reply":"2023-11-12T11:35:07.357013Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def prepare_midyear_loaders(train_batch_size=1):\n    train_datasets = []\n    val_datasets = []\n    for i in range(4, 10):\n        month = ''\n        if i < 10:\n            month = '0' + str(i)\n        else:\n            month = str(i)\n        path = PATH + '2021-' + month + '-train.hdf5'\n        month_dataset = RadarDataset([path])\n        train_month, val_month = torch.utils.data.random_split(month_dataset, [0.8, 0.2])\n        train_datasets.append(train_month)\n        val_datasets.append(val_month)\n    full_train_dataset = torch.utils.data.ConcatDataset([train_datasets[i] for i in range(6)])\n    train_loader = data.DataLoader(full_train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n    val_loaders = [data.DataLoader(val_datasets[i], batch_size=train_batch_size, shuffle=False, num_workers=4) for i in range(6)] \n    return train_loader, val_loaders\n    \ndef prepare_month_loaders(train_batch_size=1): #summer up\n    train_datasets = []\n    val_datasets = []\n    for i in range(1, 13):\n        month = ''\n        if i < 10:\n            month = '0' + str(i)\n        else:\n            month = str(i)\n        path = PATH + '2021-' + month + '-train.hdf5'\n        month_dataset = RadarDataset([path])\n        train_month, val_month = torch.utils.data.random_split(month_dataset, [0.8, 0.2])\n        train_datasets.append(train_month)\n        if int(month) >= 5 and int(month) <= 8:\n            train_datasets.append(train_month)\n        val_datasets.append(val_month)\n    full_train_dataset = torch.utils.data.ConcatDataset([train_datasets[i] for i in range(len(train_datasets))])\n    train_loader = data.DataLoader(full_train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n    val_loaders = [data.DataLoader(val_datasets[i], batch_size=train_batch_size, shuffle=False, num_workers=4) for i in range(12)] \n    return train_loader, val_loaders\n\n\ndef prepare_train_loader(train_batch_size=1):\n    train_dataset = RadarDataset([\n        PATH + '2021-01-train.hdf5', PATH + '2021-03-train.hdf5', PATH + '2021-04-train.hdf5',\n        PATH + '2021-06-train.hdf5', PATH + '2021-07-train.hdf5', PATH + '2021-09-train.hdf5',\n        PATH + '2021-10-train.hdf5', PATH + '2021-12-train.hdf5'])\n    \n    #train_dataset = torch.utils.data.ConcatDataset([train_dataset_0, train_dataset_1, train_dataset_2, train_dataset_3])\n    #train_data = torch.utils.random_split(train_dataset, [0.8, 0.2])\n    return data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\ndef prepare_valid_loader(valid_batch_size=1):\n    #valid_dataset = RadarDataset([PATH + '2021-08-train.hdf5'])\n    valid_dataset = RadarDataset([PATH + '2021-08-train.hdf5', PATH + '2021-05-train.hdf5', PATH + '2021-02-train.hdf5', PATH + '2021-11-train.hdf5'])\n    valid_loader = data.DataLoader(valid_dataset, batch_size=valid_batch_size, shuffle=True, num_workers=4)\n    return valid_loader\n\ndef prepare_test_loader(test_batch_size=1):\n    test_dataset = RadarDataset([PATH + '2022-test-public.hdf5'], out_seq_len=0, with_time=True)\n    test_loader = data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n    return test_loader\n\ndef evaluate_on_val(model, valid_loader):\n    rmses = np.zeros((12,), dtype=float)\n    for item in tqdm.tqdm(valid_loader):\n        inputs, target = item\n        output = model(inputs)\n        rmses += np.sum((\n            np.square(target.detach().cpu().numpy() - output.detach().cpu().numpy())\n        ) * (target.detach().cpu().numpy() != -1), axis=(0, 2, 3, 4))\n    rmses /= len(valid_loader)\n    return np.mean(np.sqrt(rmses))\n\n\ndef process_test(model, test_loader, output_file='../output.hdf5'):\n    model.eval()\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n    for index, item in tqdm.tqdm(enumerate(test_loader)):\n        (inputs, last_input_timestamp), _ = item\n        output = model(inputs)\n        with h5py.File(output_file, mode='a') as f_out:\n            for ind in range(output.shape[1]):\n                timestamp_out = str(int(last_input_timestamp[-1]) + 600 * (ind + 1))\n                f_out.create_group(timestamp_out)\n                f_out[timestamp_out].create_dataset(\n                    'intensity',\n                    data=output[0, ind, 0].detach().cpu().numpy()\n                )","metadata":{"id":"-dVKatbSeM8x","execution":{"iopub.status.busy":"2023-11-12T11:35:07.359128Z","iopub.execute_input":"2023-11-12T11:35:07.359456Z","iopub.status.idle":"2023-11-12T11:35:07.382431Z","shell.execute_reply.started":"2023-11-12T11:35:07.359430Z","shell.execute_reply":"2023-11-12T11:35:07.381401Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_loader, val_loaders = prepare_month_loaders()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"IicZrCaRWPsq","execution":{"iopub.status.busy":"2023-11-12T11:35:07.385650Z","iopub.execute_input":"2023-11-12T11:35:07.385983Z","iopub.status.idle":"2023-11-12T11:35:28.823059Z","shell.execute_reply.started":"2023-11-12T11:35:07.385957Z","shell.execute_reply":"2023-11-12T11:35:28.822048Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = torch.load('/kaggle/input/models-for-baseline/baseline_11e-4.pt') #11e-4","metadata":{"id":"X9XRvJImCuMU","execution":{"iopub.status.busy":"2023-11-12T11:36:52.355151Z","iopub.execute_input":"2023-11-12T11:36:52.356021Z","iopub.status.idle":"2023-11-12T11:36:54.823440Z","shell.execute_reply.started":"2023-11-12T11:36:52.355979Z","shell.execute_reply":"2023-11-12T11:36:54.822652Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.current_lr=3e-4\ntrainer = L.Trainer(\n    max_epochs=1\n)\ntrainer.fit(model, train_loader)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T13:11:29.160341Z","iopub.execute_input":"2023-11-12T13:11:29.161113Z","iopub.status.idle":"2023-11-12T13:49:44.679784Z","shell.execute_reply.started":"2023-11-12T13:11:29.161082Z","shell.execute_reply":"2023-11-12T13:49:44.678811Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae70809ae3443768de47dadc34e0cf7"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"ConvLSTMModel(\n  (model): Seq2Seq(\n    (sequential): Sequential(\n      (convlstm1): ConvLSTM(\n        (convLSTMCell): ConvLSTMCell(\n          (conv_int_0): Conv2d(33, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (conv_int_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (conv_refl_0): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n    )\n    (conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"for i in range(1, 13):\n    print('month', i)\n    print(evaluate_on_val(model, val_loaders[i - 1]))\n    \n","metadata":{"id":"mw4iWu-iYZjS","colab":{"base_uri":"https://localhost:8080/","height":570,"referenced_widgets":["4c2b6efebbb5454e98fb596de85d4aab","decd17c37d1c4008ad7e25736291a741","575a8d8837064bc39e530f6f92f72a98","ddf0e3d6dd0c473787c9da84b4aa812f","2a2378586a684f328359596471386c4c","ade6137503de4500a7fad90fc197bf78","815cb215b6334689a153203664270b1e","6ab2f919c96c4e67b7fd22ab024d8c77","d2addea19f8c441496fe0e37742ff010","e8d2e4595b59491dbfe71f43c1f584fe","1ccba0e73382487f9577e7a4d1b3a481"]},"outputId":"108f3bf2-d1d0-45a2-bbf1-3e8d759e46d8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.save(model, 'baseline_18e-4.pt')","metadata":{"id":"KY6DLdZinlvo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1dd1c4c2-aa9b-47fd-a4ca-e86052e9e117","execution":{"iopub.status.busy":"2023-11-12T14:01:01.554621Z","iopub.execute_input":"2023-11-12T14:01:01.555053Z","iopub.status.idle":"2023-11-12T14:01:01.564576Z","shell.execute_reply.started":"2023-11-12T14:01:01.555010Z","shell.execute_reply":"2023-11-12T14:01:01.563609Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\nevaluate_on_val(model, val_loader) #168","metadata":{"id":"ZlBqptsGm9oS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"396f1968-fe4b-470b-9c90-555787776ffd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = L.Trainer(\n    max_epochs=1\n)\ntrainer.fit(model, train_loaders[2])","metadata":{"id":"cWJlXWlxsYUy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'two_conv_with_act_3_data.pt')\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_on_val(model, val_loader) #checked","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"da4zz8GG6Yrm","outputId":"8953a789-986d-445b-ceb5-8ce40480d1bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nimport gc\ndel model\ngc.collect()\ntorch.cuda.empty_cache()\n'''","metadata":{"id":"Cdaru8HrFS1S","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0')\nmodel.to(device)","metadata":{"id":"_AO2jtcjUG4C","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = L.Trainer(\n    max_epochs=1\n)\ntrainer.fit(model, train_loaders[3])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":535,"referenced_widgets":["a717014939ba49c9a0715362dd8309bb","4c1cd253a40e491b81178d46c82a5d11","61eb63c1dd6a4cf8824ecc5eb91c3d08","3f4b82f09b0946388a0ba73022d71091","5c8d4bc596b146e3abdea6cc696c99a6","ff3922456ea440ffbf64c79a552ea72c","09cbea143f3b48549154ca2f968cbc70","9c086102011d494696cd8b463c602c8b","48631a28bd8c49b99fae65fe41075053","a150466f924d4bedad3c04980dd3927d","1ebe51a5d7be4cd1bb5847ce63f7e5c4"]},"id":"uQTZhAZsHkeM","outputId":"db849ea1-69ba-4ced-de0e-d0aebb65b640","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'rotate_full_data.pt')","metadata":{"id":"oslmLIBKHtBI","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nevaluate_on_val(model, val_loader)","metadata":{"id":"yF3K5eCJdQuc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = L.Trainer(\n    max_epochs=1\n)\ntrainer.fit(model, train_loaders[4])","metadata":{"colab":{"background_save":true},"id":"UUBCWuX95qJ_","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nevaluate_on_val(model, val_loader) #checked","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.is_available())","metadata":{"id":"tUXbGJfM_AxR","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = torch.load('two_conv_with_act_2_data.pt')","metadata":{"id":"338GKAtuXYxn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(data.Dataset):\n\n    def __init__(self, list_of_files, in_seq_len=4, out_seq_len=12, mode='overlap', with_time=False):\n        self.in_seq_len = in_seq_len\n        self.out_seq_len = out_seq_len\n        self.seq_len = in_seq_len + out_seq_len\n        self.with_time = with_time\n        self.__prepare_timestamps_mapping(list_of_files)\n        self.__prepare_sequences(mode)\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, index):\n        data = []\n        for timestamp in self.sequences[index]:\n            with h5py.File(self.timestamp_to_file[timestamp]) as d:\n                data.append(np.array(d[timestamp]['intensity']))\n        data = np.expand_dims(data, axis=1)\n        data[data == -1e6] = 0\n        data[data == -2e6] = -1\n        inputs = data[:self.in_seq_len]\n        targets = data[self.in_seq_len:]\n        if self.with_time:\n            return (inputs, self.sequences[index][-1]), targets\n        else:\n            return inputs, targets\n\n    def __prepare_timestamps_mapping(self, list_of_files):\n        self.timestamp_to_file = {}\n        for filename in list_of_files:\n            with h5py.File(filename) as d:\n                self.timestamp_to_file = {\n                    **self.timestamp_to_file,\n                    **dict(map(lambda x: (x, filename), d.keys()))\n                }\n\n    def __prepare_sequences(self, mode):\n        timestamps = np.unique(sorted(self.timestamp_to_file.keys()))\n        if mode == 'sequentially':\n            self.sequences = [\n                timestamps[index * self.seq_len: (index + 1) * self.seq_len]\n                for index in range(len(timestamps) // self.seq_len)\n            ]\n        elif mode == 'overlap':\n            self.sequences = [\n                timestamps[index: index + self.seq_len]\n                for index in range(len(timestamps) - self.seq_len + 1)\n            ] \n        else:\n            raise Exception(f'Unknown mode {mode}')\n        self.sequences = list(filter(\n            lambda x: int(x[-1]) - int(x[0]) == (self.seq_len - 1) * 600,\n            self.sequences\n        ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_test_loader(test_batch_size=1):\n    test_dataset = RadarDataset(['/kaggle/input/nowcasting-yandex-cup/2022-test-public.hdf5'], out_seq_len=0, with_time=True)\n    test_loader = data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=2)\n    return test_loader","metadata":{"id":"CH1WtjCbyy4h","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = prepare_test_loader()\nmodel.to(device)\nprocess_test(model, test_loader, output_file='augmented_base.hdf5')","metadata":{"id":"52fi4qAZy7QH","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'augmented_base.hdf5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"events = []\nintensity = []\nradial_velocity = []\nreflectivity = []\n\nwith h5py.File('/kaggle/input/nowcasting-yandex-cup/2021-01-train.hdf5', mode='r') as dataset:\n    timestamps = sorted(dataset.keys())[:6]\n    for timestamp in timestamps:\n        radial_velocity.append(np.array(dataset[timestamp]['radial_velocity'][0]))\nradial_velocity = np.array(radial_velocity)\n\nradial_velocity[radial_velocity == -2e6] = -2\nradial_velocity[radial_velocity == -1e6] = -1","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, axs = plt.subplots(1, len(radial_velocity), figsize=(20, 2))\nfor index in range(len(radial_velocity)):\n    axs[index].imshow(radial_velocity[index])\n    axs[index].set_title(timestamps[index])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\n\n# Define the input tensor\ninput_tensor = torch.randn(10, 252, 252)\n\n# Define the convolutional layer\nconv_layer = nn.Conv2d(in_channels=10, out_channels=32, kernel_size=3)\n\n# Apply the convolutional layer to the input tensor\noutput_tensor = conv_layer(input_tensor)\n\n# Convert the output tensor to a numpy array\noutput_array = output_tensor.detach().numpy()\n\n# Reshape the numpy array to length 32\nreshaped_array = np.reshape(output_array, (32,))\n\n# Print the resulting numpy array\nprint(reshaped_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    def forward(self, X, H_prev, C_prev):\n        int_X, ev_X = torch.chunk(X, chunks=2, dim=1)\n        int_H_prev, ev_H_prev = torch.chunk(H_prev, chunks=2, dim=1)\n        conv_int_output = self.conv_int(torch.cat([int_X, int_H_prev], dim=1))\n        conv_ev_output = self.conv_ev(torch.cat([ev_X, ev_H_prev], dim=1))\n        i_conv_int, f_conv_int, C_conv_int, o_conv_int = torch.chunk(conv_int_output, chunks=4, dim=1)\n        i_conv_ev, f_conv_ev, C_conv_ev, o_conv_ev = torch.chunk(conv_ev_output, chunks=4, dim=1)\n        input_gate = torch.sigmoid(torch.cat([i_conv_int, i_conv_ev], dim=1))\n        forget_gate = torch.sigmoid(torch.cat([f_conv_int,f_conv_ev], dim=1))\n        output_gate = torch.sigmoid(torch.cat([o_conv_int, o_conv_ev], dim=1))\n        C_conv = torch.cat([C_conv_int, C_conv_ev], dim=1)\n        C = forget_gate * C_prev + input_gate * self.activation(C_conv)\n        H = output_gate * self.activation(C)\n        return H, C","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvLSTMCell(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n\n        if activation == 'tanh':\n            self.activation = torch.tanh\n        elif activation == 'relu':\n            self.activation = torch.relu\n            \n        self.conv_wind = nn.Conv2d(\n            in_channels= 10 + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding= padding\n        )\n        \n        self.conv_refl = nn.Conv2d(\n            in_channels= 10 + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding= padding\n        )\n\n        self.conv_int = nn.Conv2d(\n            in_channels=in_channels + out_channels,\n            out_channels=4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n\n    def forward(self, X, H_prev, C_prev):\n        int_X = X[:,0:1, :, :]\n        wind_X= X[:,1:11, :, :]\n        refl_X= X[:,11:, :, :]\n        int_H_prev = H_prev[:,0:32, :, :]\n        wind_H_prev = H_prev[:,32:64, :, :]\n        refl_H_prev = H_prev[:,64:96, :, :]\n\n        conv_int_output = self.conv_int(torch.cat([int_X, int_H_prev], dim=1))\n        conv_wind_output = self.conv_wind(torch.cat([wind_X, wind_H_prev], dim=1))\n        conv_refl_output = self.conv_refl(torch.cat([refl_X, refl_H_prev], dim=1))\n        \n        i_conv_int, f_conv_int, C_conv_int, o_conv_int = torch.chunk(conv_int_output, chunks=4, dim=1)\n        i_conv_wind, f_conv_wind, C_conv_wind, o_conv_wind = torch.chunk(conv_wind_output, chunks=4, dim=1)\n        i_conv_refl, f_conv_refl, C_conv_refl, o_conv_refl = torch.chunk(conv_refl_output, chunks=4, dim=1)\n\n        input_gate = torch.sigmoid(torch.cat([i_conv_int, i_conv_wind, i_conv_refl], dim=1))\n        forget_gate = torch.sigmoid(torch.cat([f_conv_int, f_conv_wind, f_conv_refl], dim=1))\n        output_gate = torch.sigmoid(torch.cat([o_conv_int,  o_conv_wind, o_conv_refl], dim=1))\n        C_conv = torch.cat([C_conv_int, C_conv_wind, C_conv_refl], dim=1)\n        C = forget_gate * C_prev + input_gate * self.activation(C_conv)\n        H = output_gate * self.activation(C)\n\n\n        '''X.shape: torch.Size([1, 4, 252, 252])\nH_prev.shape: torch.Size([1, 128, 252, 252])\nC_prev.shape: torch.Size([1, 128, 252, 252])\nint_X.shape: torch.Size([1, 1, 252, 252])\nconv_int_output.shape: torch.Size([1, 128, 252, 252])\ni_conv_int.shape: torch.Size([1, 32, 252, 252])\ninput_gate.shape: torch.Size([1, 128, 252, 252])\nH.shape: torch.Size([1, 128, 252, 252])\nC.shape: torch.Size([1, 128, 252, 252])'''\n\n        return H, C\n\n\nclass ConvLSTM(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n        self.out_channels = out_channels\n        self.convLSTMCell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding, activation)\n\n    def forward(self, X):\n        batch_size, seq_len, _, height, width = X.size()\n        output = torch.zeros(batch_size, seq_len, 3 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        H = torch.zeros(batch_size, 3 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        C = torch.zeros(batch_size, 3 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        for time_step in range(seq_len):\n            H, C = self.convLSTMCell(X[:, time_step], H, C)\n            output[:, time_step] = H\n        return output\n\n\nclass Seq2Seq(nn.Module):\n\n    def __init__(\n        self, num_channels, num_kernels, kernel_size, padding, activation, num_layers, out_seq_len\n    ):\n        super().__init__()\n        self.out_seq_len = out_seq_len\n\n        self.activation = torch.relu\n        self.sequential = nn.Sequential()\n        self.sequential.add_module(\n            'convlstm1',\n            ConvLSTM(\n                in_channels=num_channels,\n                out_channels=num_kernels,\n                kernel_size=kernel_size,\n                padding=padding,\n                activation=activation\n            )\n        )\n        for layer_index in range(2, num_layers + 1):\n            self.sequential.add_module(\n                f'convlstm{layer_index}',\n                ConvLSTM(\n                    in_channels=num_kernels,\n                    out_channels=num_kernels,\n                    kernel_size=kernel_size,\n                    padding=padding,\n                    activation=activation\n                )\n            )\n        self.conv = nn.Conv2d(\n            in_channels=3*num_kernels,\n            out_channels=num_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n\n    def forward(self, X):\n        batch_size, seq_len, num_channels, height, width = X.size()\n        inputs = torch.zeros(\n            batch_size, seq_len + self.out_seq_len - 1, num_channels, height, width,\n            device=self.conv.weight.device\n        )\n        inputs[:, :seq_len] = X\n        output = self.sequential(inputs)\n        output = torch.stack([\n            self.conv(output[:, index + seq_len - 1])\n            for index in range(self.out_seq_len)\n        ], dim=1)\n        return output\n\n\nclass ConvLSTMModel(L.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.model = Seq2Seq(\n            num_channels=1,\n            num_kernels=32,\n            kernel_size=(3, 3),\n            padding=(1, 1),\n            activation='relu',\n            num_layers=1,\n            out_seq_len=12\n        )\n\n    def forward(self, x):\n        x = x.to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        output = self.model(x)\n        return output\n\n    def training_step(self, batch):\n        x, y = batch\n        out = self.forward(x)\n        out[y == -1] = -1\n        loss = F.mse_loss(out, y)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n        return optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n                \n                targets.append(np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['intensity'])), k=self.rotate, dims=(0, 1))))\n                data.append(np.array([np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['intensity'])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][0])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][1])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][2])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][3])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][4])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][5])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][6])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][7])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][8])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['radial_velocity'][9])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][0])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][1])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][2])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][3])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][4])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][5])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][6])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][7])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][8])), k=self.rotate, dims=(0, 1))),\n                                      np.array(torch.rot90(torch.tensor(np.array(d[timestamp]['reflectivity'][9])), k=self.rotate, dims=(0, 1)))]))\n                '''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}