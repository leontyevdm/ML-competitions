{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6810533,"sourceType":"datasetVersion","datasetId":3917981}],"dockerImageVersionId":30580,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning\nPATH = '/kaggle/input/yandex-cup-ml-23-nowcasting/ML Cup 2023 Weather/train/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-12T14:59:29.798225Z","iopub.execute_input":"2023-11-12T14:59:29.799272Z","iopub.status.idle":"2023-11-12T14:59:41.289209Z","shell.execute_reply.started":"2023-11-12T14:59:29.799236Z","shell.execute_reply":"2023-11-12T14:59:41.288028Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.24.3)\nRequirement already satisfied: torch>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.0.0)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.1)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\nRequirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2023.10.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.2.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.5.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport tqdm\nimport pytorch_lightning as L","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:59:41.293684Z","iopub.execute_input":"2023-11-12T14:59:41.293989Z","iopub.status.idle":"2023-11-12T14:59:41.299467Z","shell.execute_reply.started":"2023-11-12T14:59:41.293960Z","shell.execute_reply":"2023-11-12T14:59:41.298436Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning import seed_everything\nimport random\nseed=7\nseed_everything(seed, workers=True)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:59:41.300733Z","iopub.execute_input":"2023-11-12T14:59:41.301082Z","iopub.status.idle":"2023-11-12T14:59:41.318314Z","shell.execute_reply.started":"2023-11-12T14:59:41.301048Z","shell.execute_reply":"2023-11-12T14:59:41.317480Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class RadarDataset(data.Dataset):\n\n    def __init__(self, list_of_files, in_seq_len=4, out_seq_len=12, mode='sequentially', rotate = 0, with_time=False):\n        self.in_seq_len = in_seq_len\n        self.out_seq_len = out_seq_len\n        self.seq_len = in_seq_len + out_seq_len\n        self.with_time = with_time\n        self.__prepare_timestamps_mapping(list_of_files)\n        self.__prepare_sequences(mode)\n        self.rotate = rotate\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, index):\n        to_append = []\n        data = []\n        targets = []\n        for timestamp in self.sequences[index]:\n            with h5py.File(self.timestamp_to_file[timestamp]) as d:\n                targets.append(np.array(torch.rot90(torch.tensor(np.array([d[timestamp]['intensity']])), self.rotate)))\n                data.append(np.array([d[timestamp]['intensity'], d[timestamp]['reflectivity'][0], d[timestamp]['reflectivity'][1], d[timestamp]['reflectivity'][2], \n                                      d[timestamp]['reflectivity'][3], d[timestamp]['reflectivity'][4], d[timestamp]['reflectivity'][5],\n                                     d[timestamp]['reflectivity'][6], d[timestamp]['reflectivity'][7],\n                                     d[timestamp]['radial_velocity'][0], d[timestamp]['radial_velocity'][1], d[timestamp]['radial_velocity'][2],\n                                     d[timestamp]['radial_velocity'][3], d[timestamp]['radial_velocity'][4],\n                                     d[timestamp]['radial_velocity'][5], d[timestamp]['radial_velocity'][6], d[timestamp]['radial_velocity'][7]]))\n                #data.append(np.array([d[timestamp]['intensity'], d[timestamp]['events'], d[timestamp]['reflectivity'][0]]))\n                \n        data = np.array(data)\n        targets = np.array(targets)\n        #data = np.expand_dims(data, axis=1)\n        #targets = np.expand_dims(targets, axis=1)\n        data[data == -1e6] = 0\n        data[data == -2e6] = -1\n        targets[targets == -1e6] = 0\n        targets[targets == -2e6] = -1\n        inputs = data[:self.in_seq_len]\n        targets = targets[self.in_seq_len:]\n        if self.with_time:\n            return (inputs, self.sequences[index][-1]), targets\n        else:\n            return inputs, targets\n\n    def __prepare_timestamps_mapping(self, list_of_files):\n        self.timestamp_to_file = {}\n        for filename in list_of_files:\n            with h5py.File(filename) as d:\n                self.timestamp_to_file = {\n                    **self.timestamp_to_file,\n                    **dict(map(lambda x: (x, filename), d.keys()))\n                }\n\n    def __prepare_sequences(self, mode):\n        timestamps = np.unique(sorted(self.timestamp_to_file.keys()))\n        if mode == 'sequentially':\n            self.sequences = [\n                timestamps[index * self.seq_len: (index + 1) * self.seq_len]\n                for index in range(len(timestamps) // self.seq_len)\n            ]\n        elif mode == 'overlap':\n            self.sequences = [\n                timestamps[index: index + self.seq_len]\n                for index in range(len(timestamps) - self.seq_len + 1)\n            ] \n        else:\n            raise Exception(f'Unknown mode {mode}')\n        self.sequences = list(filter(\n            lambda x: int(x[-1]) - int(x[0]) == (self.seq_len - 1) * 600,\n            self.sequences\n        ))","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:59:41.321015Z","iopub.execute_input":"2023-11-12T14:59:41.321485Z","iopub.status.idle":"2023-11-12T14:59:41.340787Z","shell.execute_reply.started":"2023-11-12T14:59:41.321452Z","shell.execute_reply":"2023-11-12T14:59:41.339884Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class ConvLSTMCell(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n\n        if activation == 'tanh':\n            self.activation = torch.tanh\n        elif activation == 'relu':\n            self.activation = torch.relu\n\n        self.conv_int_0 = nn.Conv2d(\n            in_channels=in_channels + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        \n        self.conv_int_1 = nn.Conv2d(\n            in_channels= 4 * out_channels,\n            out_channels=4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        self.conv_refl_0 = nn.Conv2d(\n            in_channels=16 + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        \n    def forward(self, X, H_prev, C_prev):\n        \n        int_X = X[:,0:1, :, :]\n        refl_X= X[:,1:, :, :]\n        H_prev_int, H_prev_refl = torch.chunk(H_prev, chunks=2, dim=1)\n        conv_int_output = self.conv_int_1(self.activation(self.conv_int_0(torch.cat([int_X, H_prev_int], dim=1))))\n        conv_refl_output = self.conv_refl_0(torch.cat([refl_X, H_prev_refl], dim=1))\n        \n        i_conv_int, f_conv_int, C_conv_int, o_conv_int = torch.chunk(conv_int_output, chunks=4, dim=1)\n        i_conv_refl, f_conv_refl, C_conv_refl, o_conv_refl = torch.chunk(conv_refl_output, chunks=4, dim=1)\n\n\n        input_gate = torch.sigmoid(torch.cat([i_conv_int, i_conv_refl], dim=1))\n        forget_gate = torch.sigmoid(torch.cat([f_conv_int, f_conv_refl], dim=1))\n        output_gate = torch.sigmoid(torch.cat([o_conv_int, o_conv_refl], dim=1))\n        C_conv = torch.cat([C_conv_int, C_conv_refl], dim=1)\n        C = forget_gate * C_prev + input_gate * self.activation(C_conv)\n        H = output_gate * self.activation(C)\n        return H, C\n\n\nclass ConvLSTM(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n        self.out_channels = out_channels\n        self.convLSTMCell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding, activation)\n\n    def forward(self, X):\n        batch_size, seq_len, _, height, width = X.size()\n        output = torch.zeros(batch_size, seq_len, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        H = torch.zeros(batch_size, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        C = torch.zeros(batch_size, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        for time_step in range(seq_len):\n            H, C = self.convLSTMCell(X[:, time_step], H, C)\n            output[:, time_step] = H\n        return output\n\n\nclass Seq2Seq(nn.Module):\n\n    def __init__(\n        self, num_channels, num_kernels, kernel_size, padding, activation, num_layers, out_seq_len\n    ):\n        super().__init__()\n        self.out_seq_len = out_seq_len\n\n        self.activation = torch.relu\n        self.sequential = nn.Sequential()\n        self.sequential.add_module(\n            'convlstm1',\n            ConvLSTM(\n                in_channels=num_channels,\n                out_channels=num_kernels,\n                kernel_size=kernel_size,\n                padding=padding,\n                activation=activation\n            )\n        )\n        for layer_index in range(2, num_layers + 1):\n            self.sequential.add_module(\n                f'convlstm{layer_index}',\n                ConvLSTM(\n                    in_channels=num_kernels,\n                    out_channels=num_kernels,\n                    kernel_size=kernel_size,\n                    padding=padding,\n                    activation=activation\n                )\n            )\n        self.conv = nn.Conv2d(\n            in_channels=2 * num_kernels,\n            out_channels=num_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n\n    def forward(self, X):\n        batch_size, seq_len, num_channels, height, width = X.size()\n        inputs = torch.zeros(\n            batch_size, seq_len + self.out_seq_len - 1, num_channels, height, width,\n            device=self.conv.weight.device\n        )\n        inputs[:, :seq_len] = X\n        output = self.sequential(inputs)\n        output = torch.stack([\n            self.conv(output[:, index + seq_len - 1])\n            for index in range(self.out_seq_len)\n        ], dim=1)\n        return output\n\n\nclass ConvLSTMModel(L.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.model = Seq2Seq(\n            num_channels=1,\n            num_kernels=32,\n            kernel_size=(3, 3),\n            padding=(1, 1),\n            activation='relu',\n            num_layers=1,\n            out_seq_len=12\n        )\n\n    def forward(self, x):\n        x = x.to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        output = self.model(x)\n        return output\n\n    def training_step(self, batch):\n        x, y = batch\n        out = self.forward(x)\n        out[y == -1] = -1\n        loss = F.mse_loss(out, y)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=5e-4)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:59:41.342245Z","iopub.execute_input":"2023-11-12T14:59:41.342520Z","iopub.status.idle":"2023-11-12T14:59:41.370638Z","shell.execute_reply.started":"2023-11-12T14:59:41.342490Z","shell.execute_reply":"2023-11-12T14:59:41.369855Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def prepare_winter_loaders(train_batch_size=1): #summer up\n    train_datasets = []\n    val_datasets = []\n    for i in range(1, 5):\n        month = '0' + str(i)\n        path = PATH + '2021-' + month + '-train.hdf5'\n        month_dataset = RadarDataset([path])\n        #train_month, val_month = torch.utils.data.random_split(month_dataset, [0.8, 0.2])\n        train_datasets.append(month_dataset)\n        #val_datasets.append(val_month)\n    for i in range(9, 13):\n        if i <10:\n            month = '0' + str(i)\n        else:\n            month = str(month)\n        path = PATH + '2021-' + month + '-train.hdf5'\n        month_dataset = RadarDataset([path])\n        #train_month, val_month = torch.utils.data.random_split(month_dataset, [0.8, 0.2])\n        train_datasets.append(month_dataset)\n        #val_datasets.append(val_month)\n    full_train_dataset = torch.utils.data.ConcatDataset([train_datasets[i] for i in range(len(train_datasets))])\n    train_loader = data.DataLoader(full_train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n    #val_loaders = [data.DataLoader(val_datasets[i], batch_size=train_batch_size, shuffle=False, num_workers=4) for i in range(len(val_datasets))] \n    return train_loader#, val_loaders","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:01:17.514434Z","iopub.execute_input":"2023-11-12T15:01:17.514943Z","iopub.status.idle":"2023-11-12T15:01:17.523836Z","shell.execute_reply.started":"2023-11-12T15:01:17.514910Z","shell.execute_reply":"2023-11-12T15:01:17.522849Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"winter_train = prepare_winter_loaders()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:01:24.391880Z","iopub.execute_input":"2023-11-12T15:01:24.392519Z","iopub.status.idle":"2023-11-12T15:01:37.252645Z","shell.execute_reply.started":"2023-11-12T15:01:24.392486Z","shell.execute_reply":"2023-11-12T15:01:37.251762Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"winter_model = ConvLSTMModel()","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:01:37.254180Z","iopub.execute_input":"2023-11-12T15:01:37.254469Z","iopub.status.idle":"2023-11-12T15:01:37.263143Z","shell.execute_reply.started":"2023-11-12T15:01:37.254444Z","shell.execute_reply":"2023-11-12T15:01:37.262238Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"winter_model.current_lr = 3e-4\ntrainer = L.Trainer(\n    max_epochs=1\n)\ntrainer.fit(winter_model, winter_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:52:10.278506Z","iopub.execute_input":"2023-11-12T15:52:10.279423Z","iopub.status.idle":"2023-11-12T16:16:43.581369Z","shell.execute_reply.started":"2023-11-12T15:52:10.279386Z","shell.execute_reply":"2023-11-12T16:16:43.580341Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27be269c249d449c9e1e0440152bb639"}},"metadata":{}}]},{"cell_type":"code","source":"torch.save(winter_model, 'winter_no_val_9e-4.pt')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T16:16:49.475798Z","iopub.execute_input":"2023-11-12T16:16:49.476204Z","iopub.status.idle":"2023-11-12T16:16:49.485698Z","shell.execute_reply.started":"2023-11-12T16:16:49.476167Z","shell.execute_reply":"2023-11-12T16:16:49.484697Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}