{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6877002,"sourceType":"datasetVersion","datasetId":3951530}],"dockerImageVersionId":30580,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-lightning\nPATH = '/kaggle/input/nowcasting-yandex-cup/'","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:09:48.282773Z","iopub.execute_input":"2023-11-12T14:09:48.283114Z","iopub.status.idle":"2023-11-12T14:10:01.399235Z","shell.execute_reply.started":"2023-11-12T14:09:48.283087Z","shell.execute_reply":"2023-11-12T14:10:01.398088Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.24.3)\nRequirement already satisfied: torch>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2.0.0)\nRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.66.1)\nRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (6.0.1)\nRequirement already satisfied: fsspec[http]>2021.06.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (2023.10.0)\nRequirement already satisfied: torchmetrics>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (1.2.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (21.3)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (4.5.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning) (0.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->pytorch-lightning) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (3.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.12.0->pytorch-lightning) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.12.0->pytorch-lightning) (2.1.3)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.12.0->pytorch-lightning) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:10:01.401192Z","iopub.execute_input":"2023-11-12T14:10:01.401544Z","iopub.status.idle":"2023-11-12T14:10:01.410391Z","shell.execute_reply.started":"2023-11-12T14:10:01.401508Z","shell.execute_reply":"2023-11-12T14:10:01.409423Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport tqdm\nimport pytorch_lightning as L","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:10:01.411349Z","iopub.execute_input":"2023-11-12T14:10:01.411639Z","iopub.status.idle":"2023-11-12T14:10:07.970577Z","shell.execute_reply.started":"2023-11-12T14:10:01.411616Z","shell.execute_reply":"2023-11-12T14:10:07.969734Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning import seed_everything\nimport random\nseed=7\nseed_everything(seed, workers=True)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2023-11-12T14:10:07.972455Z","iopub.execute_input":"2023-11-12T14:10:07.972892Z","iopub.status.idle":"2023-11-12T14:10:07.983977Z","shell.execute_reply.started":"2023-11-12T14:10:07.972866Z","shell.execute_reply":"2023-11-12T14:10:07.983268Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class RadarDataset(data.Dataset):\n\n    def __init__(self, list_of_files, in_seq_len=4, out_seq_len=12, mode='overlap', rotate = 0, with_time=False):\n        self.in_seq_len = in_seq_len\n        self.out_seq_len = out_seq_len\n        self.seq_len = in_seq_len + out_seq_len\n        self.with_time = with_time\n        self.__prepare_timestamps_mapping(list_of_files)\n        self.__prepare_sequences(mode)\n        self.rotate = rotate\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, index):\n        to_append = []\n        data = []\n        targets = []\n        for timestamp in self.sequences[index]:\n            with h5py.File(self.timestamp_to_file[timestamp]) as d:\n                targets.append(np.array(torch.rot90(torch.tensor(np.array([d[timestamp]['intensity']])), self.rotate)))\n                data.append(np.array([d[timestamp]['intensity'], d[timestamp]['reflectivity'][0], d[timestamp]['reflectivity'][1], d[timestamp]['reflectivity'][2], \n                                      d[timestamp]['reflectivity'][3], d[timestamp]['reflectivity'][4], d[timestamp]['reflectivity'][5],\n                                     d[timestamp]['reflectivity'][6], d[timestamp]['reflectivity'][7],\n                                     d[timestamp]['radial_velocity'][0], d[timestamp]['radial_velocity'][1], d[timestamp]['radial_velocity'][2],\n                                     d[timestamp]['radial_velocity'][3], d[timestamp]['radial_velocity'][4],\n                                     d[timestamp]['radial_velocity'][5], d[timestamp]['radial_velocity'][6], d[timestamp]['radial_velocity'][7]]))\n                #data.append(np.array([d[timestamp]['intensity'], d[timestamp]['events'], d[timestamp]['reflectivity'][0]]))\n                \n        data = np.array(data)\n        targets = np.array(targets)\n        #data = np.expand_dims(data, axis=1)\n        #targets = np.expand_dims(targets, axis=1)\n        data[data == -1e6] = 0\n        data[data == -2e6] = -1\n        targets[targets == -1e6] = 0\n        targets[targets == -2e6] = -1\n        inputs = data[:self.in_seq_len]\n        targets = targets[self.in_seq_len:]\n        if self.with_time:\n            return (inputs, self.sequences[index][-1]), targets\n        else:\n            return inputs, targets\n\n    def __prepare_timestamps_mapping(self, list_of_files):\n        self.timestamp_to_file = {}\n        for filename in list_of_files:\n            with h5py.File(filename) as d:\n                self.timestamp_to_file = {\n                    **self.timestamp_to_file,\n                    **dict(map(lambda x: (x, filename), d.keys()))\n                }\n\n    def __prepare_sequences(self, mode):\n        timestamps = np.unique(sorted(self.timestamp_to_file.keys()))\n        if mode == 'sequentially':\n            self.sequences = [\n                timestamps[index * self.seq_len: (index + 1) * self.seq_len]\n                for index in range(len(timestamps) // self.seq_len)\n            ]\n        elif mode == 'overlap':\n            self.sequences = [\n                timestamps[index: index + self.seq_len]\n                for index in range(len(timestamps) - self.seq_len + 1)\n            ] \n        else:\n            raise Exception(f'Unknown mode {mode}')\n        self.sequences = list(filter(\n            lambda x: int(x[-1]) - int(x[0]) == (self.seq_len - 1) * 600,\n            self.sequences\n        ))","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:40:54.908095Z","iopub.execute_input":"2023-11-12T15:40:54.908832Z","iopub.status.idle":"2023-11-12T15:40:54.927155Z","shell.execute_reply.started":"2023-11-12T15:40:54.908799Z","shell.execute_reply":"2023-11-12T15:40:54.926127Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"class ConvLSTMCell(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n\n        if activation == 'tanh':\n            self.activation = torch.tanh\n        elif activation == 'relu':\n            self.activation = torch.relu\n\n        self.conv_int_0 = nn.Conv2d(\n            in_channels=in_channels + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        \n        self.conv_int_1 = nn.Conv2d(\n            in_channels= 4 * out_channels,\n            out_channels=4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        self.conv_refl_0 = nn.Conv2d(\n            in_channels=16 + out_channels,\n            out_channels= 4 * out_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n        \n    def forward(self, X, H_prev, C_prev):\n        \n        int_X = X[:,0:1, :, :]\n        refl_X= X[:,1:, :, :]\n        H_prev_int, H_prev_refl = torch.chunk(H_prev, chunks=2, dim=1)\n        conv_int_output = self.conv_int_1(self.activation(self.conv_int_0(torch.cat([int_X, H_prev_int], dim=1))))\n        conv_refl_output = self.conv_refl_0(torch.cat([refl_X, H_prev_refl], dim=1))\n        \n        i_conv_int, f_conv_int, C_conv_int, o_conv_int = torch.chunk(conv_int_output, chunks=4, dim=1)\n        i_conv_refl, f_conv_refl, C_conv_refl, o_conv_refl = torch.chunk(conv_refl_output, chunks=4, dim=1)\n\n\n        input_gate = torch.sigmoid(torch.cat([i_conv_int, i_conv_refl], dim=1))\n        forget_gate = torch.sigmoid(torch.cat([f_conv_int, f_conv_refl], dim=1))\n        output_gate = torch.sigmoid(torch.cat([o_conv_int, o_conv_refl], dim=1))\n        C_conv = torch.cat([C_conv_int, C_conv_refl], dim=1)\n        C = forget_gate * C_prev + input_gate * self.activation(C_conv)\n        H = output_gate * self.activation(C)\n        return H, C\n\n\nclass ConvLSTM(nn.Module):\n\n    def __init__(self, in_channels, out_channels, kernel_size, padding, activation):\n        super().__init__()\n        self.out_channels = out_channels\n        self.convLSTMCell = ConvLSTMCell(in_channels, out_channels, kernel_size, padding, activation)\n\n    def forward(self, X):\n        batch_size, seq_len, _, height, width = X.size()\n        output = torch.zeros(batch_size, seq_len, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        H = torch.zeros(batch_size, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        C = torch.zeros(batch_size, 2 * self.out_channels, height, width, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        for time_step in range(seq_len):\n            H, C = self.convLSTMCell(X[:, time_step], H, C)\n            output[:, time_step] = H\n        return output\n\n\nclass Seq2Seq(nn.Module):\n\n    def __init__(\n        self, num_channels, num_kernels, kernel_size, padding, activation, num_layers, out_seq_len\n    ):\n        super().__init__()\n        self.out_seq_len = out_seq_len\n\n        self.activation = torch.relu\n        self.sequential = nn.Sequential()\n        self.sequential.add_module(\n            'convlstm1',\n            ConvLSTM(\n                in_channels=num_channels,\n                out_channels=num_kernels,\n                kernel_size=kernel_size,\n                padding=padding,\n                activation=activation\n            )\n        )\n        for layer_index in range(2, num_layers + 1):\n            self.sequential.add_module(\n                f'convlstm{layer_index}',\n                ConvLSTM(\n                    in_channels=num_kernels,\n                    out_channels=num_kernels,\n                    kernel_size=kernel_size,\n                    padding=padding,\n                    activation=activation\n                )\n            )\n        self.conv = nn.Conv2d(\n            in_channels=2 * num_kernels,\n            out_channels=num_channels,\n            kernel_size=kernel_size,\n            padding=padding\n        )\n\n    def forward(self, X):\n        batch_size, seq_len, num_channels, height, width = X.size()\n        inputs = torch.zeros(\n            batch_size, seq_len + self.out_seq_len - 1, num_channels, height, width,\n            device=self.conv.weight.device\n        )\n        inputs[:, :seq_len] = X\n        output = self.sequential(inputs)\n        output = torch.stack([\n            self.conv(output[:, index + seq_len - 1])\n            for index in range(self.out_seq_len)\n        ], dim=1)\n        return output\n\n\nclass ConvLSTMModel(L.LightningModule):\n\n    def __init__(self):\n        super().__init__()\n        self.model = Seq2Seq(\n            num_channels=1,\n            num_kernels=32,\n            kernel_size=(3, 3),\n            padding=(1, 1),\n            activation='relu',\n            num_layers=1,\n            out_seq_len=12\n        )\n\n    def forward(self, x):\n        x = x.to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n        output = self.model(x)\n        return output\n\n    def training_step(self, batch):\n        x, y = batch\n        out = self.forward(x)\n        out[y == -1] = -1\n        loss = F.mse_loss(out, y)\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=3e-4)\n        return optimizer","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:40:52.411086Z","iopub.execute_input":"2023-11-12T15:40:52.411434Z","iopub.status.idle":"2023-11-12T15:40:52.440211Z","shell.execute_reply.started":"2023-11-12T15:40:52.411407Z","shell.execute_reply":"2023-11-12T15:40:52.439184Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def prepare_summer_loaders(train_batch_size=1): #summer up\n    train_datasets = []\n    val_datasets = []\n    for i in range(5, 9):\n        month = '0' + str(i)\n        path = PATH + '2021-' + month + '-train.hdf5'\n        month_dataset = RadarDataset([path])\n        #train_month, val_month = torch.utils.data.random_split(month_dataset, [0.8, 0.2])\n        train_datasets.append(month_dataset)\n        #val_datasets.append(val_month)\n    full_train_dataset = torch.utils.data.ConcatDataset([train_datasets[i] for i in range(len(train_datasets))])\n    train_loader = data.DataLoader(full_train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=4)\n    #val_loaders = [data.DataLoader(val_datasets[i], batch_size=train_batch_size, shuffle=False, num_workers=4) for i in range(len(val_datasets))] \n    return train_loader#, val_loaders","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:41:03.054406Z","iopub.execute_input":"2023-11-12T15:41:03.054779Z","iopub.status.idle":"2023-11-12T15:41:03.061386Z","shell.execute_reply.started":"2023-11-12T15:41:03.054750Z","shell.execute_reply":"2023-11-12T15:41:03.060462Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"summer_train = prepare_summer_loaders()  #, summer_vals\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:41:05.946308Z","iopub.execute_input":"2023-11-12T15:41:05.946659Z","iopub.status.idle":"2023-11-12T15:41:13.618343Z","shell.execute_reply.started":"2023-11-12T15:41:05.946633Z","shell.execute_reply":"2023-11-12T15:41:13.617549Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"summer_model = ConvLSTMModel()","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:41:17.274558Z","iopub.execute_input":"2023-11-12T15:41:17.274929Z","iopub.status.idle":"2023-11-12T15:41:17.282296Z","shell.execute_reply.started":"2023-11-12T15:41:17.274899Z","shell.execute_reply":"2023-11-12T15:41:17.281327Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"summer_model.current_lr = 3e-4\ntrainer = L.Trainer(\n    max_epochs=1\n)\nsummer_model.to(device)\ntrainer.fit(summer_model, summer_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:41:18.811471Z","iopub.execute_input":"2023-11-12T15:41:18.811874Z","iopub.status.idle":"2023-11-12T18:18:32.430612Z","shell.execute_reply.started":"2023-11-12T15:41:18.811845Z","shell.execute_reply":"2023-11-12T18:18:32.429220Z"},"trusted":true},"execution_count":52,"outputs":[{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd6e021915b14f89a8c65e73547df687"}},"metadata":{}}]},{"cell_type":"code","source":"def evaluate_on_val(model, valid_loader):\n    rmses = np.zeros((12,), dtype=float)\n    for item in tqdm.tqdm(valid_loader):\n        inputs, target = item\n        output = model(inputs)\n        \n        rmses += np.sum((\n            np.square(target.detach().cpu().numpy() - output.detach().cpu().numpy())\n        ) * (target.detach().cpu().numpy() != -1), axis=(0, 2, 3, 4))\n    rmses /= len(valid_loader)\n    return np.mean(np.sqrt(rmses))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-11-11T22:47:19.577997Z","iopub.execute_input":"2023-11-11T22:47:19.578712Z","iopub.status.idle":"2023-11-11T22:47:20.589942Z","shell.execute_reply.started":"2023-11-11T22:47:19.578669Z","shell.execute_reply":"2023-11-11T22:47:20.589097Z"},"trusted":true},"execution_count":140,"outputs":[]},{"cell_type":"code","source":"summer_model.to(device) #5e-4 + 3e-4\nfor month in range(5, 9):\n    print('month', month)\n    print(evaluate_on_val(summer_model, summer_vals[month - 5]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(summer_model, 'summer_no_val_8e-4')","metadata":{"execution":{"iopub.status.busy":"2023-11-12T15:40:14.524266Z","iopub.execute_input":"2023-11-12T15:40:14.524815Z","iopub.status.idle":"2023-11-12T15:40:14.533590Z","shell.execute_reply.started":"2023-11-12T15:40:14.524774Z","shell.execute_reply":"2023-11-12T15:40:14.532541Z"},"trusted":true},"execution_count":45,"outputs":[]}]}