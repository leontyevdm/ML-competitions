{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d71d9c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-24T13:58:20.659624Z",
     "iopub.status.busy": "2024-07-24T13:58:20.659212Z",
     "iopub.status.idle": "2024-07-24T13:58:57.565067Z",
     "shell.execute_reply": "2024-07-24T13:58:57.563531Z"
    },
    "papermill": {
     "duration": 36.922667,
     "end_time": "2024-07-24T13:58:57.568142",
     "exception": false,
     "start_time": "2024-07-24T13:58:20.645475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\r\n",
      "Installing collected packages: Whoosh\r\n",
      "Successfully installed Whoosh-2.7.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc286905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:58:57.595929Z",
     "iopub.status.busy": "2024-07-24T13:58:57.594486Z",
     "iopub.status.idle": "2024-07-24T13:59:33.640468Z",
     "shell.execute_reply": "2024-07-24T13:59:33.639262Z"
    },
    "papermill": {
     "duration": 36.06293,
     "end_time": "2024-07-24T13:59:33.643574",
     "exception": false,
     "start_time": "2024-07-24T13:58:57.580644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/whoosh-wheel-2-7-4/Whoosh-2.7.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.10/site-packages (from Whoosh==2.7.4) (1.5.2)\n",
      "Whoosh is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import dill\n",
    "import polars as pl\n",
    "import whoosh_utils\n",
    "import random\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56bbb728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:59:33.672000Z",
     "iopub.status.busy": "2024-07-24T13:59:33.670771Z",
     "iopub.status.idle": "2024-07-24T13:59:33.677939Z",
     "shell.execute_reply": "2024-07-24T13:59:33.676879Z"
    },
    "papermill": {
     "duration": 0.023655,
     "end_time": "2024-07-24T13:59:33.680749",
     "exception": false,
     "start_time": "2024-07-24T13:59:33.657094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5271d89d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T13:59:33.707701Z",
     "iopub.status.busy": "2024-07-24T13:59:33.707242Z",
     "iopub.status.idle": "2024-07-24T14:01:03.909368Z",
     "shell.execute_reply": "2024-07-24T14:01:03.908137Z"
    },
    "papermill": {
     "duration": 90.220953,
     "end_time": "2024-07-24T14:01:03.914155",
     "exception": false,
     "start_time": "2024-07-24T13:59:33.693202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3746791706.py:57: DeprecationWarning: `DataFrame.melt` is deprecated. Use `unpivot` instead, with `index` instead of `id_vars` and `on` instead of `value_vars`\n",
      "  all_pub = test.melt().get_column(\"value\").unique()\n",
      "100%|██████████| 365/365 [00:00<00:00, 576.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ended\n",
      "collected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/3746791706.py:90: DeprecationWarning: `DataFrame.melt` is deprecated. Use `unpivot` instead, with `index` instead of `id_vars` and `on` instead of `value_vars`\n",
      "  all_pub_nums = neigbours[:,1:].melt()[:,1].unique()\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from tqdm import tqdm\n",
    "interactive= False\n",
    "if interactive:\n",
    "    pub_num = pl.read_csv('/kaggle/input/uspto-explainable-ai-validation-index/validation/validation_publication_numbers.csv')[:2500]\n",
    "    test = pub_num #pl.read_csv(comp_data_dir / \"test.csv\")\n",
    "    neigbours_small = pl.read_csv('/kaggle/input/uspto-explainable-ai-validation-index/neighbors_small.csv')\n",
    "    test = test.join(neigbours_small, on=\"publication_number\", how=\"left\")\n",
    "\n",
    "    all_pub = test.melt().get_column(\"value\").unique()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    comp_data_dir = Path(\"/kaggle/input/uspto-explainable-ai\")\n",
    "    meta = pl.scan_parquet(comp_data_dir / \"patent_metadata.parquet\")\n",
    "    meta = (\n",
    "        meta.with_columns(\n",
    "            pl.col(\"publication_date\").dt.year().alias(\"year\"),\n",
    "            pl.col(\"publication_date\").dt.month().alias(\"month\"),\n",
    "        )\n",
    "    #.filter(pl.col(\"publication_date\") >= pl.date(1975, 1, 1))\n",
    "        .rename({\"cpc_codes\": \"cpc\"})\n",
    "        .collect()\n",
    "    )\n",
    "    meta = meta.filter(pl.col(\"publication_number\").is_in(all_pub))\n",
    "    patents = []\n",
    "    n_unique = meta.select([\"year\", \"month\"]).n_unique()\n",
    "    for (year, month), _ in tqdm(meta.group_by([\"year\", \"month\"]), total=n_unique):\n",
    "        patent_path = comp_data_dir / f\"patent_data/{year}_{month}.parquet\"\n",
    "        patent = pl.scan_parquet(patent_path).select(pl.exclude([\"claims\", \"description\"]))\n",
    "        patent = patent.filter(pl.col(\"publication_number\").is_in(all_pub))\n",
    "        patents.append(patent)\n",
    "    print('for ended')\n",
    "    patent = pl.concat(patents) #pl.LazyFrame\n",
    "    patent = patent.with_columns(\n",
    "        pl.lit(\"\").alias(\"claims\"),\n",
    "        pl.lit(\"\").alias(\"description\"),\n",
    "    )\n",
    "    meta_with_text = (\n",
    "        meta.lazy().join(patent, on=\"publication_number\", how=\"left\")\n",
    "    )\n",
    "    meta_with_text = meta_with_text.collect(streaming=True)\n",
    "    print('collected')\n",
    "    all_pub_nums = neigbours_small[:,1:].melt()[:,1].unique()\n",
    "    test_meta = (meta_with_text.filter(pl.col('publication_number').is_in(all_pub_nums)).unique(subset=['publication_number']))\n",
    "    all_pub_nums = test_meta.get_column('publication_number')\n",
    "    del meta_with_text\n",
    "    del neigbours_small\n",
    "    del patent\n",
    "    del patents\n",
    "    gc.collect()\n",
    "else:\n",
    "    comp_data_dir = Path(\"/kaggle/input/uspto-explainable-ai\")\n",
    "    test = pl.read_csv(comp_data_dir / \"test.csv\")\n",
    "    neigbours = pl.read_csv('/kaggle/input/uspto-explainable-ai/nearest_neighbors.csv')\n",
    "    test = test.join(neigbours, on=\"publication_number\", how=\"left\")\n",
    "    all_pub = test.melt().get_column(\"value\").unique()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    meta = pl.scan_parquet(comp_data_dir / \"patent_metadata.parquet\")\n",
    "    meta = (\n",
    "        meta.with_columns(\n",
    "            pl.col(\"publication_date\").dt.year().alias(\"year\"),\n",
    "            pl.col(\"publication_date\").dt.month().alias(\"month\"),\n",
    "        )\n",
    "        .rename({\"cpc_codes\": \"cpc\"})\n",
    "        .collect()\n",
    "    )\n",
    "    meta = meta.filter(pl.col(\"publication_number\").is_in(all_pub))\n",
    "    patents = []\n",
    "    n_unique = meta.select([\"year\", \"month\"]).n_unique()\n",
    "    for (year, month), _ in tqdm(meta.group_by([\"year\", \"month\"]), total=n_unique):\n",
    "        patent_path = comp_data_dir / f\"patent_data/{year}_{month}.parquet\"\n",
    "        patent = pl.scan_parquet(patent_path).select(pl.exclude([\"claims\", \"description\"]))\n",
    "        patent = patent.filter(pl.col(\"publication_number\").is_in(all_pub))\n",
    "        patents.append(patent)\n",
    "    print('for ended')\n",
    "    patent = pl.concat(patents) #pl.LazyFrame\n",
    "    patent = patent.with_columns(\n",
    "        pl.lit(\"\").alias(\"claims\"),\n",
    "        pl.lit(\"\").alias(\"description\"),\n",
    "    )\n",
    "    meta_with_text = (\n",
    "        meta.lazy().join(patent, on=\"publication_number\", how=\"left\")\n",
    "    )\n",
    "    meta_with_text = meta_with_text.collect(streaming=True)\n",
    "    print('collected')\n",
    "    neigbours = neigbours.filter(neigbours.get_column('publication_number').is_in(test.get_column('publication_number')))\n",
    "    all_pub_nums = neigbours[:,1:].melt()[:,1].unique()\n",
    "    test_meta = (meta_with_text.filter(pl.col('publication_number').is_in(all_pub_nums)).unique(subset=['publication_number']))\n",
    "    del patents\n",
    "    del neigbours\n",
    "    del patent\n",
    "    del meta_with_text\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2679b2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:01:03.948784Z",
     "iopub.status.busy": "2024-07-24T14:01:03.948264Z",
     "iopub.status.idle": "2024-07-24T14:01:03.960565Z",
     "shell.execute_reply": "2024-07-24T14:01:03.958393Z"
    },
    "papermill": {
     "duration": 0.031598,
     "end_time": "2024-07-24T14:01:03.963894",
     "exception": false,
     "start_time": "2024-07-24T14:01:03.932296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "def save_as_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        dill.dump(obj, f)\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754e1cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:01:03.997801Z",
     "iopub.status.busy": "2024-07-24T14:01:03.996478Z",
     "iopub.status.idle": "2024-07-24T14:01:04.006634Z",
     "shell.execute_reply": "2024-07-24T14:01:04.004988Z"
    },
    "papermill": {
     "duration": 0.031672,
     "end_time": "2024-07-24T14:01:04.009877",
     "exception": false,
     "start_time": "2024-07-24T14:01:03.978205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if interactive:\n",
    "    test_idx = whoosh_utils.load_index(\"/kaggle/input/uspto-explainable-ai-validation-index/validation/validation_index\")\n",
    "    searcher = whoosh_utils.get_searcher(test_idx)\n",
    "    qp = whoosh_utils.get_query_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "340ab736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:01:04.040574Z",
     "iopub.status.busy": "2024-07-24T14:01:04.040094Z",
     "iopub.status.idle": "2024-07-24T14:01:04.053540Z",
     "shell.execute_reply": "2024-07-24T14:01:04.051774Z"
    },
    "papermill": {
     "duration": 0.033045,
     "end_time": "2024-07-24T14:01:04.057170",
     "exception": false,
     "start_time": "2024-07-24T14:01:04.024125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle(ti, frequency_dict):\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    ti_set = set()\n",
    "    ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "    w_prev = ''\n",
    "    for w in ti_cleaned:\n",
    "        if w in BRS_STOPWORDS or len(w) < 2:\n",
    "            continue\n",
    "        if w not in ti_set:\n",
    "            ti_set.add(w)\n",
    "            if w not in frequency_dict:\n",
    "                frequency_dict[w] = 1\n",
    "            else:\n",
    "                frequency_dict[w] += 1\n",
    "        if w_prev != '':\n",
    "            if w_prev + ' ' + w not in ti_set:\n",
    "                ti_set.add(w_prev + ' ' + w)\n",
    "                if w_prev + ' ' + w not in frequency_dict:\n",
    "                    frequency_dict[w_prev + ' ' + w] = 1\n",
    "                else:\n",
    "                    frequency_dict[w_prev + ' ' + w] += 1\n",
    "        w_prev = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b4b4484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:01:04.091339Z",
     "iopub.status.busy": "2024-07-24T14:01:04.089317Z",
     "iopub.status.idle": "2024-07-24T14:01:04.120655Z",
     "shell.execute_reply": "2024-07-24T14:01:04.118246Z"
    },
    "papermill": {
     "duration": 0.053437,
     "end_time": "2024-07-24T14:01:04.125442",
     "exception": false,
     "start_time": "2024-07-24T14:01:04.072005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "def handle_cross(first, second, frequency_dict, first_dict, second_dict):\n",
    "    BRS_STOPWORDS = {'an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', \n",
    "                     'of', 'on', 'such', 'that', 'the', 'their', 'then', \n",
    "                     'there', 'these', 'they', 'this', 'to', 'was', 'will'}\n",
    "\n",
    "    # Use a single regex findall call and filter in one go\n",
    "    first_cleaned = {word for word in re.findall(r'\\b\\w+\\b', first.lower()) \n",
    "                     if word not in BRS_STOPWORDS and len(word) > 1 and word in first_dict}\n",
    "    second_cleaned = {word for word in re.findall(r'\\b\\w+\\b', second.lower()) \n",
    "                      if word not in BRS_STOPWORDS and len(word) > 1 and word in second_dict}\n",
    "\n",
    "    for w1, w2 in product(first_cleaned, second_cleaned):\n",
    "        frequency_dict[(w1, w2)] += 1\n",
    "        \n",
    "def handle_single(first, frequency_dict, first_dict):\n",
    "    BRS_STOPWORDS = {'an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', \n",
    "                     'of', 'on', 'such', 'that', 'the', 'their', 'then', \n",
    "                     'there', 'these', 'they', 'this', 'to', 'was', 'will'}\n",
    "\n",
    "    # Use a single regex findall call and filter in one go\n",
    "    first_cleaned = {word for word in re.findall(r'\\b\\w+\\b', first.lower()) \n",
    "                     if word not in BRS_STOPWORDS and len(word) > 1 and word in first_dict}\n",
    "\n",
    "    for w1, w2 in product(first_cleaned, first_cleaned):\n",
    "        frequency_dict[(w1, w2)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a27d8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:01:04.160397Z",
     "iopub.status.busy": "2024-07-24T14:01:04.159946Z",
     "iopub.status.idle": "2024-07-24T14:20:48.492524Z",
     "shell.execute_reply": "2024-07-24T14:20:48.490415Z"
    },
    "papermill": {
     "duration": 1184.351571,
     "end_time": "2024-07-24T14:20:48.495980",
     "exception": false,
     "start_time": "2024-07-24T14:01:04.144409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "361it [19:39,  3.27s/it]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "load_dicts = False\n",
    "if load_dicts:\n",
    "    desc_freqs = load_pickle('/kaggle/input/claims-freqs-with-bigrams-for-random-state-0/full_desc_freqs_with_bigrams_first_2500.pkl')\n",
    "    claims_freqs = load_pickle('/kaggle/input/claims-freqs-with-bigrams-for-random-state-0/full_claims_freqs_with_bigrams_first_2500.pkl')\n",
    "else:\n",
    "    p_meta = pl.read_parquet(os.path.join(comp_data_dir, \"patent_metadata.parquet\"), columns=[\"publication_number\", \"publication_date\", \"cpc_codes\"])\n",
    "    p_meta = p_meta.filter(pl.col(\"publication_number\").is_in(all_pub_nums))\n",
    "\n",
    "    p_meta = p_meta.with_columns(pl.col(\"publication_date\").dt.year().alias(\"year\"))\n",
    "    p_meta = p_meta.with_columns(pl.col(\"publication_date\").dt.month().alias(\"month\"))\n",
    "    #claims_pairs_freqs = defaultdict(int)\n",
    "    desc_freqs = dict()\n",
    "    claims_freqs = dict()\n",
    "    c = 0\n",
    "    for (year, month), meta_df in tqdm(p_meta.group_by([\"year\", \"month\"], maintain_order=True)):\n",
    "        #meta_df = meta_df.with_columns(pl.col(\"cpc_codes\").list.join(\" \"))\n",
    "        patents = pl.read_parquet(os.path.join(comp_data_dir, f\"patent_data/{year}_{month}.parquet\"))\n",
    "        patents = patents.filter(pl.col(\"publication_number\").is_in(meta_df[\"publication_number\"]))\n",
    "        for i in range(meta_df.shape[0]):\n",
    "            d = dict()\n",
    "            p = patents.filter(pl.col(\"publication_number\") == meta_df[i, \"publication_number\"])\n",
    "            if p.shape[0] > 0:\n",
    "                desc = p[0, \"description\"]\n",
    "                #handle_single(desc, desc_pairs_freqs, desc_freqs)\n",
    "                handle(desc, desc_freqs)\n",
    "                claims = p[0, \"claims\"]\n",
    "                handle(claims, claims_freqs)\n",
    "                #handle_single(claims, claims_pairs_freqs, claims_freqs)\n",
    "            \n",
    "                #handle_cross(claims, desc, claims_desc_freqs, claims_freqs, desc_freqs)\n",
    "                del desc\n",
    "                del claims\n",
    "            del p\n",
    "        del patents\n",
    "    del p_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dad30c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:48.594987Z",
     "iopub.status.busy": "2024-07-24T14:20:48.594524Z",
     "iopub.status.idle": "2024-07-24T14:20:48.600497Z",
     "shell.execute_reply": "2024-07-24T14:20:48.599269Z"
    },
    "papermill": {
     "duration": 0.05923,
     "end_time": "2024-07-24T14:20:48.603366",
     "exception": false,
     "start_time": "2024-07-24T14:20:48.544136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save_as_pickle(desc_freqs, 'full_desc_freqs_with_bigrams_first_2500.pkl')\n",
    "#save_as_pickle(claims_freqs, 'full_claims_freqs_with_bigrams_first_2500.pkl')\n",
    "#save_as_pickle(claims_desc_freqs, 'claims500_desc500_freqs_first_2500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8170c1c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:48.703048Z",
     "iopub.status.busy": "2024-07-24T14:20:48.702590Z",
     "iopub.status.idle": "2024-07-24T14:20:49.161754Z",
     "shell.execute_reply": "2024-07-24T14:20:49.160581Z"
    },
    "papermill": {
     "duration": 0.512338,
     "end_time": "2024-07-24T14:20:49.164704",
     "exception": false,
     "start_time": "2024-07-24T14:20:48.652366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "claims_freqs = {key: value for key, value in claims_freqs.items() if value <= 100}\n",
    "desc_freqs = {key: value for key, value in desc_freqs.items() if value <= 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce79f17a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:49.261656Z",
     "iopub.status.busy": "2024-07-24T14:20:49.261268Z",
     "iopub.status.idle": "2024-07-24T14:20:49.489851Z",
     "shell.execute_reply": "2024-07-24T14:20:49.488525Z"
    },
    "papermill": {
     "duration": 0.280179,
     "end_time": "2024-07-24T14:20:49.492872",
     "exception": false,
     "start_time": "2024-07-24T14:20:49.212693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "def extract_claims(pb_year, pb_month, cur_pb):\n",
    "    if 1790 <= pb_year <= 1999:\n",
    "        folder = '/kaggle/input/claims1790to1999'\n",
    "    elif 2000 <= pb_year <= 2011:\n",
    "        folder = '/kaggle/input/2000-to-2011'\n",
    "    elif 2012 <= pb_year <= 2023:\n",
    "        folder = '/kaggle/input/claims2012to2023'\n",
    "    \n",
    "    with h5py.File(f'{folder}/{pb_year}_{pb_month}.h5', 'r') as h5:\n",
    "        if cur_pb in h5:\n",
    "            data = h5[cur_pb][:]\n",
    "            h5_detd = data.tobytes().decode()\n",
    "        else:\n",
    "            h5_detd = ''\n",
    "    if h5_detd == None:\n",
    "        h5_detd = ''\n",
    "    return h5_detd\n",
    "\n",
    "def extract_desc(pb_year, pb_month, cur_pb):\n",
    "    if 1975 <= pb_year <= 1994:\n",
    "        folder = '/kaggle/input/1975up1994'\n",
    "    elif 1995 <= pb_year <= 2004:\n",
    "        folder = '/kaggle/input/1995up2004'\n",
    "    elif 2005 <= pb_year <= 2009:\n",
    "        folder = '/kaggle/input/2005up2009'\n",
    "    elif 1700 <= pb_year <= 1929:\n",
    "        folder = '/kaggle/input/1700up1929'\n",
    "    elif 1930 <= pb_year <= 1974:\n",
    "        folder = '/kaggle/input/1930up1974'\n",
    "    elif 2010 <= pb_year <= 2013:\n",
    "        folder = '/kaggle/input/2010up2013'\n",
    "    elif 2014 <= pb_year <= 2016:\n",
    "        folder = '/kaggle/input/2014up2016'\n",
    "    elif 2017 <= pb_year <= 2019:\n",
    "        folder = '/kaggle/input/2017up2019'\n",
    "    elif 2020 <= pb_year <= 2021:\n",
    "        folder = '/kaggle/input/2020up2021'\n",
    "    elif pb_year == 2022:\n",
    "        folder = '/kaggle/input/2022up2022'\n",
    "    elif pb_year == 2023:\n",
    "        folder = '/kaggle/input/2023up2023'\n",
    "    \n",
    "    with h5py.File(f'{folder}/{pb_year}_{pb_month}.h5', 'r') as h5:\n",
    "        if cur_pb in h5:\n",
    "            data = h5[cur_pb][:]\n",
    "            h5_detd = data.tobytes().decode()\n",
    "        else:\n",
    "            h5_detd = ''\n",
    "    if h5_detd == None:\n",
    "        h5_detd = ''\n",
    "    return h5_detd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2860bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:49.589993Z",
     "iopub.status.busy": "2024-07-24T14:20:49.589558Z",
     "iopub.status.idle": "2024-07-24T14:20:49.602843Z",
     "shell.execute_reply": "2024-07-24T14:20:49.601612Z"
    },
    "papermill": {
     "duration": 0.065001,
     "end_time": "2024-07-24T14:20:49.605796",
     "exception": false,
     "start_time": "2024-07-24T14:20:49.540795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def ap50(preds: list[str], labels: list[str]) -> float:\n",
    "    precisions = list()\n",
    "    n_found = 0\n",
    "    for e, i in enumerate(preds):\n",
    "        if i in labels:\n",
    "            n_found += 1\n",
    "        precisions.append(n_found / (e + 1))  # this is the line that is probably incorrect for competition\n",
    "    return sum(precisions) / 50\n",
    "\n",
    "def count_intersection(cand, target):\n",
    "    return set(cand).intersection(set(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd325236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:49.706190Z",
     "iopub.status.busy": "2024-07-24T14:20:49.705649Z",
     "iopub.status.idle": "2024-07-24T14:20:49.713896Z",
     "shell.execute_reply": "2024-07-24T14:20:49.712611Z"
    },
    "papermill": {
     "duration": 0.06166,
     "end_time": "2024-07-24T14:20:49.716397",
     "exception": false,
     "start_time": "2024-07-24T14:20:49.654737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_query(query: str, qp, searcher, target, results_limit=50) -> list:\n",
    "    if len(query) > 10_000:\n",
    "        raise ValueError('Query length at exceeds 10,000 characters.')\n",
    "    if 'id:' in query:\n",
    "        raise ValueError('Searching for specific patent IDs is banned.')\n",
    "\n",
    "    to_search = qp.parse(query)\n",
    "    results = searcher.search(to_search, limit=results_limit)\n",
    "    results = [x['id'] for x in results]\n",
    "    #print([i for i in range(len(results)) if results[i] in target])\n",
    "    assert len(results) <= results_limit\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5c90a88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:49.813858Z",
     "iopub.status.busy": "2024-07-24T14:20:49.813446Z",
     "iopub.status.idle": "2024-07-24T14:20:49.819891Z",
     "shell.execute_reply": "2024-07-24T14:20:49.818869Z"
    },
    "papermill": {
     "duration": 0.058022,
     "end_time": "2024-07-24T14:20:49.822271",
     "exception": false,
     "start_time": "2024-07-24T14:20:49.764249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_year_and_month(single_pb, patent_metadata):\n",
    "    pb_meta = patent_metadata.filter(patent_metadata.get_column('publication_number') == single_pb)\n",
    "    pb_pub_date = pb_meta.get_column('publication_date')[0]\n",
    "    pb_year, pb_month = pb_pub_date.year, pb_pub_date.month\n",
    "    return pb_year, pb_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c384d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:49.921650Z",
     "iopub.status.busy": "2024-07-24T14:20:49.921119Z",
     "iopub.status.idle": "2024-07-24T14:20:49.929471Z",
     "shell.execute_reply": "2024-07-24T14:20:49.928156Z"
    },
    "papermill": {
     "duration": 0.06212,
     "end_time": "2024-07-24T14:20:49.932176",
     "exception": false,
     "start_time": "2024-07-24T14:20:49.870056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_claims_and_desc_frame(target, test_meta):\n",
    "    frame = pl.DataFrame()\n",
    "    for tar in target:\n",
    "        year, month = get_year_and_month(tar, test_meta)\n",
    "        cur_claim = extract_claims(year, month, tar)\n",
    "        cur_desc = extract_desc(year, month, tar)\n",
    "        new_frame = pl.DataFrame({'claims': [cur_claim], 'desc': [cur_desc], 'publication_number': tar})\n",
    "        frame = frame.vstack(new_frame)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4b9ff9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:50.032476Z",
     "iopub.status.busy": "2024-07-24T14:20:50.032007Z",
     "iopub.status.idle": "2024-07-24T14:20:50.055563Z",
     "shell.execute_reply": "2024-07-24T14:20:50.054358Z"
    },
    "papermill": {
     "duration": 0.077458,
     "end_time": "2024-07-24T14:20:50.058477",
     "exception": false,
     "start_time": "2024-07-24T14:20:49.981019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_ti_ab_freq_dicts(meta_i, col1, col2, pair_frequency_dict, field1, field2):\n",
    "    rare_words = dict()\n",
    "    rare_freqs = dict()\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    NUMBER_REGEX = re.compile(r'^(\\d+|\\d{1,3}(,\\d{3})*)(\\.\\d+)?$')\n",
    "    rare_dicts = dict()\n",
    "    titles = meta_i.get_column(col1)\n",
    "    abss = meta_i.get_column(col2)\n",
    "    pub_nums = meta_i.get_column('publication_number')\n",
    "    for (ti, ab, pub_num) in zip(titles, abss, pub_nums):\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        ab_cleaned = re.findall(r'\\b\\w+\\b', ab.lower())\n",
    "        cur_rare_dict = dict()\n",
    "        cur_used_set = set()\n",
    "        for w1 in ti_cleaned:\n",
    "            if w1 in BRS_STOPWORDS or len(w1) < 2 or NUMBER_REGEX.match(w1):\n",
    "                continue\n",
    "            for w2 in ab_cleaned:\n",
    "                if w2 in BRS_STOPWORDS or len(w2) < 2 or NUMBER_REGEX.match(w2):\n",
    "                    continue\n",
    "                w = (w1, w2)\n",
    "                if pair_frequency_dict[w] < 50 and w not in cur_used_set:\n",
    "                    cur_used_set.add(w)\n",
    "                    rare_words[w] = pair_frequency_dict[w]\n",
    "                    cur_rare_dict[field1 + ':' + w[0] + ' ' + field2 + ':' + w[1]] = pair_frequency_dict[w]\n",
    "                    if w in rare_freqs:\n",
    "                        rare_freqs[w] += 1\n",
    "                    else:\n",
    "                        rare_freqs[w] = 1\n",
    "        \n",
    "        rare_dicts[pub_num] = cur_rare_dict\n",
    "    ideal_match = []\n",
    "    #print(rare_freqs)\n",
    "    for key, value in rare_freqs.items():\n",
    "        if rare_words[key] == value:\n",
    "            ideal_match.append(key)\n",
    "    return rare_dicts, set(ideal_match)\n",
    "\n",
    "def create_pairs_ti_ab(test_meta, col1, col2):\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    titles = test_meta.get_column(col1).fill_null(\"\")\n",
    "    abss = test_meta.get_column(col2).fill_null(\"\")\n",
    "\n",
    "    frequency_dict = dict()\n",
    "    for (ti, ab) in zip(titles, abss):\n",
    "        ti_set = set()\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        ab_cleaned = re.findall(r'\\b\\w+\\b', ab.lower())\n",
    "        for w in ti_cleaned:\n",
    "            if w in BRS_STOPWORDS or len(w) < 2:\n",
    "                continue\n",
    "            for w2 in ab_cleaned:\n",
    "                if w2 in BRS_STOPWORDS or len(w) < 2:\n",
    "                    continue\n",
    "                if (w, w2) not in ti_set:\n",
    "                    ti_set.add((w, w2))\n",
    "                else:\n",
    "                    continue\n",
    "                if (w, w2) not in frequency_dict:\n",
    "                    frequency_dict[w, w2] = 1\n",
    "                else:\n",
    "                    frequency_dict[w, w2] += 1\n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31d05a6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:50.156622Z",
     "iopub.status.busy": "2024-07-24T14:20:50.156181Z",
     "iopub.status.idle": "2024-07-24T14:20:50.927652Z",
     "shell.execute_reply": "2024-07-24T14:20:50.926412Z"
    },
    "papermill": {
     "duration": 0.824312,
     "end_time": "2024-07-24T14:20:50.930651",
     "exception": false,
     "start_time": "2024-07-24T14:20:50.106339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def create_pairs_diff_cols(test_meta, col1, col2):\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    titles = test_meta.get_column(col1).fill_null(\"\")\n",
    "    cpcs = test_meta.get_column(col2)\n",
    "    NUMBER_REGEX = re.compile(r'^(\\d+|\\d{1,3}(,\\d{3})*)(\\.\\d+)?$')\n",
    "    frequency_dict = dict()\n",
    "    for (ti, cur_cpc) in zip(titles, cpcs):\n",
    "        ti_set = set()\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "\n",
    "        for w in ti_cleaned:\n",
    "            if w in BRS_STOPWORDS or len(w) < 2 or NUMBER_REGEX.match(w):\n",
    "                continue\n",
    "            for w2 in cur_cpc:\n",
    "                if w2 in BRS_STOPWORDS or len(w) < 2:\n",
    "                    continue\n",
    "                if (w, w2) not in ti_set:\n",
    "                    ti_set.add((w, w2))\n",
    "                else:\n",
    "                    continue\n",
    "                if (w, w2) not in frequency_dict:\n",
    "                    frequency_dict[w, w2] = 1\n",
    "                else:\n",
    "                    frequency_dict[w, w2] += 1\n",
    "    return frequency_dict\n",
    "ti_cpc_pairs_frequency_dict = create_pairs_diff_cols(test_meta, 'title', 'cpc')\n",
    "ab_cpc_pairs_frequency_dict = create_pairs_diff_cols(test_meta, 'abstract', 'cpc')\n",
    "ti_ab_pairs_frequency_dict = create_pairs_ti_ab(test_meta, 'title', 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d832a26b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.032905Z",
     "iopub.status.busy": "2024-07-24T14:20:51.032390Z",
     "iopub.status.idle": "2024-07-24T14:20:51.047914Z",
     "shell.execute_reply": "2024-07-24T14:20:51.046808Z"
    },
    "papermill": {
     "duration": 0.070434,
     "end_time": "2024-07-24T14:20:51.051010",
     "exception": false,
     "start_time": "2024-07-24T14:20:50.980576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_diff_col_pair_freq_dicts(meta_i, col1, col2, pair_frequency_dict, field1, field2):\n",
    "    rare_words = dict()\n",
    "    rare_freqs = dict()\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    NUMBER_REGEX = re.compile(r'^(\\d+|\\d{1,3}(,\\d{3})*)(\\.\\d+)?$')\n",
    "    rare_dicts = dict()\n",
    "    titles = meta_i.get_column(col1)\n",
    "    cpcs = meta_i.get_column(col2)\n",
    "    pub_nums = meta_i.get_column('publication_number')\n",
    "    for (ti, cpc_cur, pub_num) in zip(titles, cpcs, pub_nums):\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        cur_rare_dict = dict()\n",
    "        cur_used_set = set()\n",
    "        for w1 in ti_cleaned:\n",
    "            if w1 in BRS_STOPWORDS or len(w1) < 2 or NUMBER_REGEX.match(w1):\n",
    "                continue\n",
    "            for w2 in cpc_cur:\n",
    "                if w2 in BRS_STOPWORDS or len(w2) < 2 or NUMBER_REGEX.match(w2):\n",
    "                    continue\n",
    "                w = (w1, w2)\n",
    "                if pair_frequency_dict[w] < 50 and w not in cur_used_set:\n",
    "                    cur_used_set.add(w)\n",
    "                    rare_words[w] = pair_frequency_dict[w]\n",
    "                    cur_rare_dict[field1 + ':' + w[0] + ' ' + field2 + ':' + w[1]] = pair_frequency_dict[w]\n",
    "                    if w in rare_freqs:\n",
    "                        rare_freqs[w] += 1\n",
    "                    else:\n",
    "                        rare_freqs[w] = 1\n",
    "        \n",
    "        rare_dicts[pub_num] = cur_rare_dict\n",
    "    ideal_match = []\n",
    "    #print(rare_freqs)\n",
    "    for key, value in rare_freqs.items():\n",
    "        if rare_words[key] == value:\n",
    "            ideal_match.append(key)\n",
    "    return rare_dicts, set(ideal_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab5ecbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.148717Z",
     "iopub.status.busy": "2024-07-24T14:20:51.148298Z",
     "iopub.status.idle": "2024-07-24T14:20:51.161804Z",
     "shell.execute_reply": "2024-07-24T14:20:51.160763Z"
    },
    "papermill": {
     "duration": 0.06549,
     "end_time": "2024-07-24T14:20:51.164551",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.099061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mscr_new(sets, token_counter):\n",
    "    mscr_set = set()\n",
    "    #global tokens_for_mscr\n",
    "    #sorted_sets = sorted(sets, key=len)\n",
    "    retain_fr = dict()\n",
    "    for s in sets:\n",
    "        for el in s:\n",
    "            if el in retain_fr:\n",
    "                retain_fr[el] += 1\n",
    "            else:\n",
    "                retain_fr[el] = 1\n",
    "    retain_freqs = list(dict(sorted(retain_fr.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "\n",
    "    if token_counter == 49:\n",
    "        for i in range(len(retain_freqs)):\n",
    "            if ' ' not in retain_freqs[i]:\n",
    "                return [retain_freqs[i]]\n",
    "        return []\n",
    "    if len(retain_freqs) == 0:\n",
    "        return []\n",
    "    max_freq = retain_fr[retain_freqs[0]]\n",
    "    \n",
    "    next_to_add = retain_freqs[0]\n",
    "    for i in range(len(retain_freqs)):\n",
    "        if retain_fr[retain_freqs[i]] == max_freq:\n",
    "            if ' ' not in retain_freqs[i]:\n",
    "                next_to_add = retain_freqs[i]\n",
    "                break\n",
    "    token_counter += len(next_to_add.split()) + 1\n",
    "    if token_counter >= 50:\n",
    "        return [next_to_add]\n",
    "    pruned_set = []\n",
    "    for s in sets:\n",
    "        if next_to_add not in s and len(s) > 0:\n",
    "            pruned_set.append(s)\n",
    "    if any(len(s) > 0 for s in sets):\n",
    "        return [next_to_add] + mscr_new(pruned_set, token_counter)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33fe8e4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.264074Z",
     "iopub.status.busy": "2024-07-24T14:20:51.263294Z",
     "iopub.status.idle": "2024-07-24T14:20:51.293176Z",
     "shell.execute_reply": "2024-07-24T14:20:51.291960Z"
    },
    "papermill": {
     "duration": 0.082599,
     "end_time": "2024-07-24T14:20:51.296402",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.213803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 38442.47it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from itertools import combinations\n",
    "def create_pairs_dict(test_meta, col):\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    titles = test_meta.get_column(col).fill_null(\"\")\n",
    "    frequency_dict = dict()\n",
    "    for ti in tqdm(titles):\n",
    "        ti_set = set()\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        ti_cleaned = sorted([token for token in ti_cleaned if not (token in BRS_STOPWORDS or len(token) < 2)])\n",
    "        all_pairs = combinations(ti_cleaned, 2)\n",
    "        for pair in all_pairs:\n",
    "            if (pair[0], pair[1]) in frequency_dict:\n",
    "                frequency_dict[(pair[0], pair[1])] += 1\n",
    "            else:\n",
    "                frequency_dict[(pair[0], pair[1])] = 1\n",
    "    return frequency_dict\n",
    "\n",
    "ti_pairs_frequency_dict = create_pairs_dict(test_meta, 'title')\n",
    "#ab_pairs_frequency_dict = create_pairs_dict(test_meta, 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1828f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.395476Z",
     "iopub.status.busy": "2024-07-24T14:20:51.395047Z",
     "iopub.status.idle": "2024-07-24T14:20:51.408976Z",
     "shell.execute_reply": "2024-07-24T14:20:51.407822Z"
    },
    "papermill": {
     "duration": 0.066532,
     "end_time": "2024-07-24T14:20:51.411835",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.345303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pair_freq_dicts(meta_i, col, pair_frequency_dict, field):\n",
    "    rare_words = dict()\n",
    "    rare_freqs = dict()\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    NUMBER_REGEX = re.compile(r'^(\\d+|\\d{1,3}(,\\d{3})*)(\\.\\d+)?$')\n",
    "    rare_dicts = dict()\n",
    "    titles = meta_i.get_column(col)\n",
    "    pub_nums = meta_i.get_column('publication_number')\n",
    "    for ti, pub_num in zip(titles, pub_nums):\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        ti_cleaned = sorted([token for token in ti_cleaned if not (token in BRS_STOPWORDS or len(token) < 2)])\n",
    "        cur_rare_dict = dict()\n",
    "        cur_used_set = set()\n",
    "        all_pairs = combinations(ti_cleaned, 2)\n",
    "        for w in all_pairs:\n",
    "            if NUMBER_REGEX.match(w[0]) or NUMBER_REGEX.match(w[1]):\n",
    "                continue\n",
    "            if pair_frequency_dict[w] < 50:\n",
    "                rare_words[w] = pair_frequency_dict[w]\n",
    "                cur_rare_dict[field + ':' + w[0] + ' ' + field + ':' + w[1]] = pair_frequency_dict[w]\n",
    "                if w in rare_freqs:\n",
    "                    rare_freqs[w] += 1\n",
    "                else:\n",
    "                    rare_freqs[w] = 1\n",
    "        rare_dicts[pub_num] = cur_rare_dict\n",
    "    ideal_match = []\n",
    "    #print(rare_freqs)\n",
    "    for key, value in rare_freqs.items():\n",
    "        if rare_words[key] == value: #*2\n",
    "            ideal_match.append(key)\n",
    "    return rare_dicts, set(ideal_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb7c8ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.511475Z",
     "iopub.status.busy": "2024-07-24T14:20:51.510696Z",
     "iopub.status.idle": "2024-07-24T14:20:51.531943Z",
     "shell.execute_reply": "2024-07-24T14:20:51.530539Z"
    },
    "papermill": {
     "duration": 0.074453,
     "end_time": "2024-07-24T14:20:51.534663",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.460210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_freq_dicts(meta_i, col, frequency_dict, field):\n",
    "    rare_words = dict()\n",
    "    rare_freqs = dict()\n",
    "    full_cover = dict()\n",
    "    good_cover = []\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    NUMBER_REGEX = re.compile(r'^(\\d+|\\d{1,3}(,\\d{3})*)(\\.\\d+)?$')\n",
    "    rare_dicts = dict()\n",
    "    titles = meta_i.get_column(col)\n",
    "    pub_nums = meta_i.get_column('publication_number')\n",
    "    all_used_sets = dict()\n",
    "    for (ti, pub_num) in zip(titles, pub_nums):\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        w_prev = ''\n",
    "        cur_rare_dict = dict()\n",
    "        cur_used_set = set()\n",
    "        for w in ti_cleaned:\n",
    "            if w in BRS_STOPWORDS or len(w) < 2:\n",
    "                continue\n",
    "            if NUMBER_REGEX.match(w):\n",
    "                w_prev = ''\n",
    "                continue\n",
    "            \n",
    "            if w in frequency_dict and w not in cur_used_set and frequency_dict[w] <= 50:        #ограничение на 50\n",
    "                rare_words[w] = frequency_dict[w]\n",
    "                cur_rare_dict[field + ':' + w] = frequency_dict[w]\n",
    "                if w in rare_freqs:\n",
    "                    rare_freqs[w] += 1\n",
    "                else:\n",
    "                    rare_freqs[w] = 1\n",
    "            if w not in cur_used_set:\n",
    "                if w in full_cover:\n",
    "                    full_cover[w] += 1\n",
    "                else:\n",
    "                    full_cover[w] = 1\n",
    "                    \n",
    "            if w_prev != '' and w_prev + ' ' + w in frequency_dict and w_prev + ' ' + w not in cur_used_set and frequency_dict[w_prev + ' ' + w] <= 50:\n",
    "                rare_words[w_prev + ' ' + w] = frequency_dict[w_prev + ' ' + w]\n",
    "                cur_rare_dict[field + ':\"' + w_prev + ' ' + w + '\"'] = frequency_dict[w_prev + ' ' + w]\n",
    "                if w_prev + ' ' + w in rare_freqs:\n",
    "                    rare_freqs[w_prev + ' ' + w] += 1\n",
    "                else:\n",
    "                    rare_freqs[w_prev + ' ' + w] = 1\n",
    "                    \n",
    "            if w_prev != '' and w_prev + ' ' + w not in cur_used_set:\n",
    "                if w_prev + ' ' + w in full_cover:\n",
    "                    full_cover[w_prev + ' ' + w] += 1\n",
    "                else:\n",
    "                    full_cover[w_prev + ' ' + w] = 1\n",
    "            \n",
    "            cur_used_set.add(w)\n",
    "            cur_used_set.add(w_prev + ' ' + w)\n",
    "            w_prev = w\n",
    "        #cur_rare_dict = dict(sorted(cur_rare_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "        all_used_sets[pub_num] = cur_used_set\n",
    "        rare_dicts[pub_num] = cur_rare_dict\n",
    "    ideal_match = []\n",
    "    thres = 1\n",
    "    val_thres = 1\n",
    "    if field == 'ab':\n",
    "        val_thres = 5\n",
    "    if field == 'detd' or field == 'clm':\n",
    "        thres = 1\n",
    "        val_thres = 10\n",
    "    #print(rare_freqs)\n",
    "    for key, value in rare_freqs.items():\n",
    "        if rare_words[key] == value:\n",
    "            ideal_match.append(key)\n",
    "            #good_cover.append(key)\n",
    "        #elif value / rare_words[key] >= thres and value >= val_thres:\n",
    "            #good_cover.append(key)\n",
    "    #cover_dicts = dict()\n",
    "    '''\n",
    "    for pub_num in pub_nums:\n",
    "        cover_dicts[pub_num] = set()\n",
    "    for word in good_cover:\n",
    "        for pub_num, cur_used_set in all_used_sets.items():\n",
    "            if word in cur_used_set:\n",
    "                cover_dicts[pub_num].add(word)'''\n",
    "    return rare_dicts, set(ideal_match), full_cover#, good_cover, cover_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee8614fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.633606Z",
     "iopub.status.busy": "2024-07-24T14:20:51.633217Z",
     "iopub.status.idle": "2024-07-24T14:20:51.644447Z",
     "shell.execute_reply": "2024-07-24T14:20:51.643182Z"
    },
    "papermill": {
     "duration": 0.063862,
     "end_time": "2024-07-24T14:20:51.647242",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.583380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_freq_dict_claims(claims, col):\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    titles=claims\n",
    "    frequency_dict = dict()\n",
    "    for ti in titles:\n",
    "        ti_dict = set()\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        w_prev = ''\n",
    "        for w in ti_cleaned:\n",
    "            if w in BRS_STOPWORDS or len(w) < 2:\n",
    "                continue\n",
    "            if w not in ti_set:\n",
    "                ti_set.add(w)\n",
    "                if w not in frequency_dict:\n",
    "                    frequency_dict[w] = 1\n",
    "                else:\n",
    "                    frequency_dict[w] += 1\n",
    "            if w_prev != '':\n",
    "                if w_prev + ' ' + w not in ti_set:\n",
    "                    ti_set.add(w_prev + ' ' + w)\n",
    "                    if w_prev + ' ' + w not in frequency_dict:\n",
    "                        frequency_dict[w_prev + ' ' + w] = 1\n",
    "                    else:\n",
    "                        frequency_dict[w_prev + ' ' + w] += 1\n",
    "            w_prev = w\n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "912ef871",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.747513Z",
     "iopub.status.busy": "2024-07-24T14:20:51.747118Z",
     "iopub.status.idle": "2024-07-24T14:20:51.814329Z",
     "shell.execute_reply": "2024-07-24T14:20:51.813096Z"
    },
    "papermill": {
     "duration": 0.120031,
     "end_time": "2024-07-24T14:20:51.817149",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.697118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def create_cpc_dict(test_meta):\n",
    "    titles = test_meta.get_column('cpc')\n",
    "    frequency_dict = dict()\n",
    "    for ti in titles:\n",
    "        for w in ti:\n",
    "            if w not in frequency_dict:\n",
    "                frequency_dict[w] = 1\n",
    "            else:\n",
    "                frequency_dict[w] += 1\n",
    "    return frequency_dict\n",
    "def create_cpc_pair_dict(test_meta):\n",
    "    titles = test_meta.get_column('cpc')\n",
    "    frequency_dict = dict()\n",
    "    for ti in titles:\n",
    "        ti_set = set()\n",
    "        for w in ti:\n",
    "            for w2 in ti:\n",
    "                if w2 == w:\n",
    "                    continue\n",
    "                if (w, w2) not in ti_set:\n",
    "                    if (w2, w) not in ti_set:\n",
    "                        ti_set.add((w, w2))\n",
    "                if (w, w2) not in frequency_dict:\n",
    "                    if (w2, w) not in frequency_dict:\n",
    "                        frequency_dict[w2, w] = 1\n",
    "                    else:\n",
    "                        frequency_dict[w2, w] += 1\n",
    "                else:\n",
    "                    frequency_dict[w, w2] += 1\n",
    "    return frequency_dict\n",
    "cpc_frequency_dict = create_cpc_dict(test_meta)\n",
    "cpc_pair_frequency_dict = create_cpc_pair_dict(test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "506a490f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:51.919337Z",
     "iopub.status.busy": "2024-07-24T14:20:51.918925Z",
     "iopub.status.idle": "2024-07-24T14:20:51.938893Z",
     "shell.execute_reply": "2024-07-24T14:20:51.937618Z"
    },
    "papermill": {
     "duration": 0.076136,
     "end_time": "2024-07-24T14:20:51.941696",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.865560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cpc_freq_dicts(meta_i, pair_frequency_dict):\n",
    "    rare_words = dict()\n",
    "    rare_freqs = dict()\n",
    "    rare_dicts = dict()\n",
    "    full_cover = dict()\n",
    "    good_cover = []\n",
    "    cpcs = meta_i.get_column('cpc')\n",
    "    pub_nums = meta_i.get_column('publication_number')\n",
    "    all_used_sets = dict()\n",
    "    for (ti, pub_num) in zip(cpcs, pub_nums):\n",
    "        cur_rare_dict = dict()\n",
    "        cur_used_set = set()\n",
    "        for w in ti:\n",
    "            if w in cur_used_set:\n",
    "                continue\n",
    "            if w in full_cover:\n",
    "                full_cover[w] += 1\n",
    "            else:\n",
    "                full_cover[w] = 1\n",
    "            if pair_frequency_dict[w] < 50:\n",
    "                cur_used_set.add(w)\n",
    "                rare_words[w] = pair_frequency_dict[w]\n",
    "                cur_rare_dict['cpc:' + w] = pair_frequency_dict[w]\n",
    "                if w in rare_freqs:\n",
    "                    rare_freqs[w] += 1\n",
    "                else:\n",
    "                    rare_freqs[w] = 1\n",
    "        all_used_sets[pub_num] = cur_used_set\n",
    "        \n",
    "        rare_dicts[pub_num] = cur_rare_dict\n",
    "    ideal_match = []\n",
    "    thres = 1\n",
    "    #print(rare_freqs)\n",
    "    for key, value in rare_freqs.items():\n",
    "        if rare_words[key] == value and value >= 1:\n",
    "            ideal_match.append(key)\n",
    "            #good_cover.append(key)\n",
    "        #elif value / rare_words[key] >= thres and value >= 1:\n",
    "            #good_cover.append(key)\n",
    "            \n",
    "            \n",
    "    '''\n",
    "    cover_dicts = dict()\n",
    "    \n",
    "    for pub_num in pub_nums:\n",
    "        cover_dicts[pub_num] = set()\n",
    "    for word in good_cover:\n",
    "        for pub_num, cur_used_set in all_used_sets.items():\n",
    "            if word in cur_used_set:\n",
    "                cover_dicts[pub_num].add(word)'''\n",
    "    return rare_dicts, set(ideal_match), full_cover#, good_cover, cover_dicts\n",
    "\n",
    "def get_cpc_pair_freq_dicts(meta_i, pair_frequency_dict):\n",
    "    rare_words = dict()\n",
    "    rare_freqs = dict()\n",
    "    rare_dicts = dict()\n",
    "    titles = meta_i.get_column('cpc')\n",
    "    pub_nums = meta_i.get_column('publication_number')\n",
    "    for (ti, pub_num) in zip(titles, pub_nums):\n",
    "        cur_rare_dict = dict()\n",
    "        cur_used_set = set()\n",
    "        for w1 in ti:\n",
    "            for w2 in ti:\n",
    "                if w1 == w2:\n",
    "                    continue\n",
    "                if (w1, w2) in pair_frequency_dict:\n",
    "                    w = (w1, w2)\n",
    "                else:\n",
    "                    w = (w2, w1)\n",
    "                if pair_frequency_dict[w] < 50 and w not in cur_used_set:\n",
    "                    cur_used_set.add(w)\n",
    "                    rare_words[w] = pair_frequency_dict[w]\n",
    "                    cur_rare_dict['cpc:' + w[0] + ' ' + 'cpc:' + w[1]] = pair_frequency_dict[w]\n",
    "                    if w in rare_freqs:\n",
    "                        rare_freqs[w] += 1\n",
    "                    else:\n",
    "                        rare_freqs[w] = 1\n",
    "        \n",
    "        rare_dicts[pub_num] = cur_rare_dict\n",
    "    ideal_match = []\n",
    "    #print(rare_freqs)\n",
    "    for key, value in rare_freqs.items():\n",
    "        if rare_words[key] == value * 2:\n",
    "            ideal_match.append(key)\n",
    "    return rare_dicts, set(ideal_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cf1b3d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:52.043848Z",
     "iopub.status.busy": "2024-07-24T14:20:52.042579Z",
     "iopub.status.idle": "2024-07-24T14:20:52.142883Z",
     "shell.execute_reply": "2024-07-24T14:20:52.141600Z"
    },
    "papermill": {
     "duration": 0.154877,
     "end_time": "2024-07-24T14:20:52.145798",
     "exception": false,
     "start_time": "2024-07-24T14:20:51.990921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def create_freq_dict(test_meta, col):\n",
    "    BRS_STOPWORDS = set(['an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', 'of', 'on', 'such',\n",
    "        'that', 'the', 'their', 'then', 'there', 'these', 'they', 'this', 'to', 'was', 'will'])\n",
    "    titles = test_meta.get_column(col).fill_null(\"\")\n",
    "    frequency_dict = dict()\n",
    "    for ti in titles:\n",
    "        ti_set = set()\n",
    "        ti_cleaned = re.findall(r'\\b\\w+\\b', ti.lower())\n",
    "        w_prev = ''\n",
    "        for w in ti_cleaned:\n",
    "            if w in BRS_STOPWORDS or len(w) < 2:\n",
    "                continue\n",
    "            if w not in ti_set:\n",
    "                ti_set.add(w)\n",
    "                if w not in frequency_dict:\n",
    "                    frequency_dict[w] = 1\n",
    "                else:\n",
    "                    frequency_dict[w] += 1\n",
    "            if w_prev != '':\n",
    "                if w_prev + ' ' + w not in ti_set:\n",
    "                    ti_set.add(w_prev + ' ' + w)\n",
    "                    if w_prev + ' ' + w not in frequency_dict:\n",
    "                        frequency_dict[w_prev + ' ' + w] = 1\n",
    "                    else:\n",
    "                        frequency_dict[w_prev + ' ' + w] += 1\n",
    "            w_prev = w\n",
    "    return frequency_dict\n",
    "ti_frequency_dict = create_freq_dict(test_meta, 'title')\n",
    "ab_frequency_dict = create_freq_dict(test_meta, 'abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8580e97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:52.247350Z",
     "iopub.status.busy": "2024-07-24T14:20:52.246195Z",
     "iopub.status.idle": "2024-07-24T14:20:52.259517Z",
     "shell.execute_reply": "2024-07-24T14:20:52.258449Z"
    },
    "papermill": {
     "duration": 0.066804,
     "end_time": "2024-07-24T14:20:52.262073",
     "exception": false,
     "start_time": "2024-07-24T14:20:52.195269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mscr_greedy(sets, token_counter, used_set):\n",
    "    mscr_set = set()\n",
    "    retain_fr = dict()\n",
    "    for s in sets:\n",
    "        for el in s:\n",
    "            if el in retain_fr and el not in used_set:\n",
    "                retain_fr[el] += 1\n",
    "            else:\n",
    "                retain_fr[el] = 1\n",
    "    retain_freqs = list(dict(sorted(retain_fr.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "    freqs_iter = 0\n",
    "    answ = []\n",
    "    length = len(retain_freqs)\n",
    "    while token_counter <= 46 and freqs_iter < length:\n",
    "        next_to_add = retain_freqs[freqs_iter]\n",
    "        cur_t = 3\n",
    "        if ' ' in next_to_add[0]:\n",
    "            cur_t += len(next_to_add[0].split()) - 1\n",
    "        if ' ' in next_to_add[1]:\n",
    "            cur_t += len(next_to_add[1].split()) - 1\n",
    "        token_counter += cur_t\n",
    "        answ.append(next_to_add)\n",
    "        freqs_iter += 1\n",
    "    if token_counter >= 47:\n",
    "        for i in range(freqs_iter, len(retain_freqs)):\n",
    "            next_to_add = retain_freqs[i]\n",
    "            cur_t = 3\n",
    "            if ' ' in next_to_add[0]:\n",
    "                cur_t += len(next_to_add[0].split()) - 1\n",
    "            if ' ' in next_to_add[1]:\n",
    "                cur_t += len(next_to_add[1].split()) - 1\n",
    "            if 50 - token_counter >= cur_t:\n",
    "                answ.append(next_to_add)\n",
    "                break\n",
    "                \n",
    "    return answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75560f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:52.362973Z",
     "iopub.status.busy": "2024-07-24T14:20:52.362530Z",
     "iopub.status.idle": "2024-07-24T14:20:52.491138Z",
     "shell.execute_reply": "2024-07-24T14:20:52.489583Z"
    },
    "papermill": {
     "duration": 0.183315,
     "end_time": "2024-07-24T14:20:52.493760",
     "exception": false,
     "start_time": "2024-07-24T14:20:52.310445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 4327.50it/s]\n"
     ]
    }
   ],
   "source": [
    "ti_freqs = dict()\n",
    "ab_freqs = dict()\n",
    "cpc_freqs = dict()\n",
    "for i in tqdm(range(len(test_meta))):\n",
    "    p = test_meta[i]\n",
    "    abstract = p[0, \"abstract\"]\n",
    "    if abstract != None:\n",
    "        handle(abstract, ab_freqs)\n",
    "        \n",
    "    title = p[0, \"title\"]\n",
    "    if title != None:\n",
    "        handle(title, ti_freqs)\n",
    "        \n",
    "    cpc = p[0, \"cpc\"]\n",
    "    for cp in cpc:\n",
    "        if cp in cpc_freqs:\n",
    "            cpc_freqs[cp] += 1\n",
    "        else:\n",
    "            cpc_freqs[cp] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b494832c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:52.594934Z",
     "iopub.status.busy": "2024-07-24T14:20:52.593960Z",
     "iopub.status.idle": "2024-07-24T14:20:52.607343Z",
     "shell.execute_reply": "2024-07-24T14:20:52.606128Z"
    },
    "papermill": {
     "duration": 0.066429,
     "end_time": "2024-07-24T14:20:52.609830",
     "exception": false,
     "start_time": "2024-07-24T14:20:52.543401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mscr_mod(sets, token_counter):\n",
    "    mscr_set = set()\n",
    "    #sorted_sets = sorted(sets, key=len)\n",
    "    retain_fr = dict()\n",
    "    for s in sets:\n",
    "        for el in s:\n",
    "            if el in retain_fr:\n",
    "                retain_fr[el] += 1\n",
    "            else:\n",
    "                retain_fr[el] = 1\n",
    "    if len(retain_fr) == 0:\n",
    "        return []\n",
    "    next_to_add = max(retain_fr, key=retain_fr.get)\n",
    "    '''\n",
    "    retain_freqs = list(dict(sorted(retain_fr.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "\n",
    "    if len(retain_freqs) == 0:\n",
    "        return []\n",
    "    max_freq = retain_fr[retain_freqs[0]]\n",
    "    next_to_add = retain_freqs[0]\n",
    "    for i in range(len(retain_freqs)):\n",
    "        if retain_fr[retain_freqs[i]] == max_freq:\n",
    "            if ' ' not in retain_freqs[i]:\n",
    "                next_to_add = retain_freqs[i]\n",
    "                break'''\n",
    "    cur_t = 3\n",
    "    if ' ' in next_to_add[0]:\n",
    "        cur_t += len(next_to_add[0].split()) - 1\n",
    "    if ' ' in next_to_add[1]:\n",
    "        cur_t += len(next_to_add[1].split()) - 1\n",
    "    if token_counter >= 46:\n",
    "        retain_freqs = list(dict(sorted(retain_fr.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "        for token in retain_freqs:\n",
    "            spl = 0\n",
    "            for t_part in token:\n",
    "                spl += len(t_part.split())\n",
    "            #print('split', spl)\n",
    "            if spl <= 50 - token_counter:\n",
    "                return [token]\n",
    "        return []\n",
    "    token_counter += cur_t\n",
    "    #print(token_counter)\n",
    "    pruned_set = []\n",
    "    for s in sets:\n",
    "        if next_to_add not in s and len(s) > 0:\n",
    "            pruned_set.append(s)\n",
    "    if any(len(s) > 0 for s in sets):\n",
    "        return [next_to_add] + mscr_mod(pruned_set, token_counter)\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "768aaa0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:52.712656Z",
     "iopub.status.busy": "2024-07-24T14:20:52.712210Z",
     "iopub.status.idle": "2024-07-24T14:20:52.725473Z",
     "shell.execute_reply": "2024-07-24T14:20:52.724348Z"
    },
    "papermill": {
     "duration": 0.068757,
     "end_time": "2024-07-24T14:20:52.728265",
     "exception": false,
     "start_time": "2024-07-24T14:20:52.659508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_desc_and_claims_pairs(frame, claims_freqs, desc_freqs):\n",
    "    cur_claims_desc = defaultdict(int)\n",
    "    BRS_STOPWORDS = {'an', 'are', 'by', 'for', 'if', 'into', 'is', 'no', 'not', \n",
    "                     'of', 'on', 'such', 'that', 'the', 'their', 'then', \n",
    "                     'there', 'these', 'they', 'this', 'to', 'was', 'will'}\n",
    "    claims_col = frame.get_column('claims')\n",
    "    desc_col = frame.get_column('desc')\n",
    "    for i in range(len(frame)):\n",
    "        first = claims_col[i]\n",
    "        second = desc_col[i]\n",
    "        first_cleaned = {word for word in re.findall(r'\\b\\w+\\b', first.lower()) \n",
    "                         if word not in BRS_STOPWORDS and len(word) > 1 and word in claims_freqs}\n",
    "        second_cleaned = {word for word in re.findall(r'\\b\\w+\\b', second.lower()) \n",
    "                          if word not in BRS_STOPWORDS and len(word) > 1 and word in desc_freqs}\n",
    "\n",
    "        for w1, w2 in product(first_cleaned, second_cleaned):\n",
    "            cur_claims_desc[(w1, w2)] += 1\n",
    "    rare_pairs = dict()\n",
    "    for key, value in cur_claims_desc.items():\n",
    "        if key in claims_desc_freqs and claims_desc_freqs[key] == value and value > 1:\n",
    "            rare_pairs[key] = value\n",
    "    return cur_claims_desc, rare_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6a1f1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:52.829172Z",
     "iopub.status.busy": "2024-07-24T14:20:52.828196Z",
     "iopub.status.idle": "2024-07-24T14:20:52.841117Z",
     "shell.execute_reply": "2024-07-24T14:20:52.839871Z"
    },
    "papermill": {
     "duration": 0.066339,
     "end_time": "2024-07-24T14:20:52.843741",
     "exception": false,
     "start_time": "2024-07-24T14:20:52.777402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def postprocess(min_set):\n",
    "    min_set = set(min_set)\n",
    "    while True:\n",
    "        first = ''\n",
    "        second = ''\n",
    "        new = ''\n",
    "        for s1 in min_set:\n",
    "            el0 = re.sub(r'[()]', '', s1[0])\n",
    "            el1 = re.sub(r'[()]', '', s1[1])\n",
    "            for s2 in min_set:\n",
    "                \n",
    "                if s1 == s2:\n",
    "                    continue\n",
    "                el3 = re.sub(r'[()]', '', s2[0])\n",
    "                el4 = re.sub(r'[()]', '', s2[1])\n",
    "                if el0 == el3 and el0 != '':\n",
    "                    first = s1\n",
    "                    second = s2\n",
    "                    new = ('((' + el0 + ')) ','((' + el1 + ' OR ' + el4 + '))')\n",
    "                elif el1 == el3 and el1 != '':\n",
    "                    first = s1\n",
    "                    second = s2\n",
    "                    new = ('((' + el1 + ')) ','((' + el0 + ' OR ' + el4 + '))')\n",
    "                elif el0 == el4 and el0 != '':\n",
    "                    first = s1\n",
    "                    second = s2\n",
    "                    new = ('((' + el0 + ')) ','((' + el1 + ' OR ' + el3 + '))')\n",
    "                elif el1 == el4 and el1 != '':\n",
    "                    first = s1\n",
    "                    second = s2\n",
    "                    new = ('((' + el1 + ')) ','((' + el0 + ') OR (' + el3 + '))')\n",
    "        if new == '':\n",
    "            break\n",
    "        else:\n",
    "            min_set -= {first}\n",
    "            min_set -= {second}\n",
    "            min_set.add(new)\n",
    "    return min_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e03c1ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:20:52.947331Z",
     "iopub.status.busy": "2024-07-24T14:20:52.946881Z",
     "iopub.status.idle": "2024-07-24T14:22:43.908096Z",
     "shell.execute_reply": "2024-07-24T14:22:43.906528Z"
    },
    "papermill": {
     "duration": 111.016078,
     "end_time": "2024-07-24T14:22:43.911182",
     "exception": false,
     "start_time": "2024-07-24T14:20:52.895104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:31<04:41, 31.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((ab:spectrometry ab:\"mass spectrometry\") OR (detd:importance detd:yield) OR ((ab:mass cpc:G01N33/6848) ) OR (detd:\"data relating\" cpc:G01N33/6842) OR (ab:sample detd:successful) OR (detd:\"similar purpose\" clm:minutes) OR (ti:chemical (ti:quantification ab:more))) OR (ab:\"mass spectrometry\" ab:spectrometry) OR ((ab:spectrometry cpc:G01N33/6848) (ab:mass)) OR ((ab:mass cpc:G01N33/6848) ab:spectrometry) OR ((ab:spectrometry cpc:G01N33/6848) ) OR (ab:spectrometry cpc:G01N33/6848) OR (ab:\"mass spectrometry\" (ab:spectrometry cpc:G01N33/6848)) OR \n",
      "447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:50<03:11, 23.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((detd:\"computing device\" detd:accessed) OR ((ti:device ab:sending) detd:multimedia) OR (ab:request detd:\"computing device\") OR (detd:multimedia detd:\"all embodiments\") OR (detd:\"cloud computing\" detd:manage) OR (detd:\"reference numbers\" ab:party) OR (ab:request detd:\"desktop computers\") OR ((ti:system ab:establishing) ab:\"transmission path\")) OR (detd:accessed detd:\"computing device\") OR (detd:multimedia (ti:device ab:sending)) OR ((ti:system ab:request) ) OR (ab:request detd:instruction) OR \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:58<01:57, 16.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "((cpc:Y02E10/50 OR ti:battery OR ab:solar OR detd:fastening OR ti:module)) OR (ab:solar cpc:Y02E10/50) OR ab:\"solar cell\" OR (ti:solar ab:solar) OR ti:solar OR (ab:cell cpc:Y02E10/50) OR detd:excellent OR cpc:H01L31/048 OR (ti:solar ab:cell) OR (ti:module ab:module) OR (ti:solar cpc:Y02E10/50) OR (ab:module cpc:Y02E10/50) OR (cpc:Y02E10/50 cpc:H01L31/048) OR (ab:solar cpc:H01L31/048) OR \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:11<01:31, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2325\n",
      "((detd:family OR detd:\"information regarding\" OR detd:activities OR detd:\"more other\" OR detd:\"device used\")) OR detd:\"any combination\" OR detd:firmware OR detd:graphical OR detd:browser OR clm:perform OR detd:visually OR detd:managed OR detd:\"data stored\" OR cpc:H04N21/44218 OR detd:world OR clm:\"further configured\" OR detd:\"programmable logic\" OR \n",
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:17<01:00, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cpc:E02F3/3486 cpc:E02F9/022) OR (detd:tilt detd:tilted) OR ((ti:machine ti:shoveling) ) OR (ti:\"loading machine\" ti:loading) OR (detd:\"embodiment my\" detd:\"figure detail\") OR (ti:material detd:\"its opposite\") OR (detd:\"means mounting\" detd:\"under control\") OR ((cpc:E02F3/657 cpc:E02F3/656) ) OR (ti:\"shovel and\" (ti:and ti:shovel)) OR (detd:\"center thereof\" detd:\"thereof lower\") OR (detd:\"extends upwardly\" detd:\"between rear\") OR (detd:\"valve element\" detd:geared) OR \n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:23<00:40, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ti:vacuum ti:\"vacuum pump\") OR (cpc:H01J41/16 detd:axially) OR (clm:field cpc:H01J41/20) OR (detd:\"electrical connection\" detd:axially) OR (detd:\"inner wall\" detd:\"power required\") OR (ab:cathode clm:chamber) OR (detd:\"inner wall\" detd:\"support shown\") OR (detd:polarity detd:\"control current\") OR ((ti:cathode cpc:H01J17/06) ) OR (cpc:H01J41/20 detd:axially) OR (detd:\"form shaped\" detd:\"supported end\") OR (detd:\"disposed inside\" detd:\"references following\") OR ((ti:electron cpc:H01J41/16) ) OR \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:29<00:25,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "((ti:meter cpc:G01F3/18) ) OR ((ti:gas ti:meter) ) OR (detd:uid ti:meter) OR (detd:passages detd:\"direct communication\") OR (detd:\"positions said\" ti:meter) OR (detd:\"plane parallel\" detd:\"axis shaft\") OR (detd:\"said head\" ti:meter) OR (clm:\"said plate\" clm:\"rotation said\") OR (detd:\"valve between\" detd:\"adjustable stop\") OR (cpc:G01F3/16 ti:meter) OR (detd:\"position all\" detd:obviated) OR (detd:\"hereby declare\" detd:dial) OR \n",
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:34<00:14,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(detd:rounded ti:paper) OR ((ti:holder ab:holder) ) OR (detd:tab detd:tabs) OR (ti:\"loose leaf\" ti:leaf) OR ((ti:clip cpc:Y10T24/206) ) OR (detd:formations ti:holder) OR (detd:\"terminal end\" detd:\"being bent\") OR (detd:\"placed top\" detd:\"two members\") OR (cpc:B42F13/006 detd:rounded) OR (detd:slipping detd:\"planes substantially\") OR (detd:\"spaced parallel\" detd:tab) OR (detd:\"ends legs\" ti:binder) OR (detd:fasteners (ti:fastener cpc:B42F13/08)) OR \n",
      "240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:46<00:08,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(((ti:reader ab:reader) ) OR ((ti:optical ab:optical) ) OR (detd:binary detd:rows) OR (ab:read ab:reading) OR (ab:scanning ab:scans) OR ((ab:each cpc:G06K7/10831) (ab:than)) OR (detd:converter detd:sensed) OR ((ti:image ab:signal) ti:terminal))) OR (detd:\"overcome problems\" detd:\"problems associated\") OR ((ab:device cpc:G07D7/121) ab:bank) OR (ab:scanning clm:capturing) OR (detd:encodes ab:\"leading edge\")) OR ((ti:optical ab:light) ) OR \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:50<00:00, 11.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "((ti:acetylene ti:\"acetylene gas\") OR (detd:snugly detd:\"limit its\") OR (detd:\"engage said\" detd:\"directly below\") OR (detd:\"hereby declare\" detd:\"others skilled\") OR ((cpc:G06F11/0715 cpc:C10H5/00) detd:tn) OR (detd:\"inwardly projecting\" detd:\"device carried\") OR (detd:\"end secured\" detd:\"downwardly against\") OR (detd:\"vertical cylinder\" detd:\"others skilled\")) OR ((ti:acetylene ti:gas) ) OR (ti:\"acetylene gas\" ti:acetylene) OR ((ti:acetylene ti:gas) ti:\"acetylene gas\") OR \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "k=12\n",
    "scores = []\n",
    "results = []\n",
    "ex_time = 0\n",
    "ban_set = {'in', 'when', 'can', 'through', 'may', 'also', 'using', 'use', 'provides', 'provided', 'includes', 'include', 'including', 'within', 'with', 'or', 'as', 'which', 'so', 'and', 'has', 'have', 'having', 'from', 'at', 'fig', 'invention', 'it', 'be', 'method', 'base', 'one'}\n",
    "for i in tqdm(range(len(test))):\n",
    "    target = test[i].to_numpy().flatten()[1:].tolist()\n",
    "    meta_i = test_meta.filter(pl.col(\"publication_number\").is_in(target))\n",
    "    st = time.time()\n",
    "    #print(meta_i)\n",
    "    \n",
    "    for j in range(len(meta_i)):\n",
    "        if meta_i[j, 'title'] == None:\n",
    "            meta_i[j, 'title'] = ''\n",
    "        if meta_i[j, 'abstract'] == None:\n",
    "            meta_i[j, 'abstract'] = ''\n",
    "          \n",
    "    rare_ti_cpc_pair_dicts, ti_cpc_pair_ideal_match = get_diff_col_pair_freq_dicts(meta_i, 'title', 'cpc', ti_cpc_pairs_frequency_dict, 'ti', 'cpc')\n",
    "    rare_ab_cpc_pair_dicts, ab_cpc_pair_ideal_match = get_diff_col_pair_freq_dicts(meta_i, 'abstract', 'cpc', ab_cpc_pairs_frequency_dict, 'ab', 'cpc')\n",
    "    rare_ti_ab_pair_dicts, ti_ab_pair_ideal_match = get_ti_ab_freq_dicts(meta_i, 'title', 'abstract', ti_ab_pairs_frequency_dict, 'ti', 'ab')\n",
    "    \n",
    "    rare_cpc_pair_dicts, cpc_pair_ideal_match = get_cpc_pair_freq_dicts(meta_i, cpc_pair_frequency_dict)\n",
    "    rare_ti_pair_dicts, ti_pair_ideal_match = get_pair_freq_dicts(meta_i, 'title', ti_pairs_frequency_dict, 'ti')\n",
    "    #rare_ab_pair_dicts, ab_pair_ideal_match = get_pair_freq_dicts(meta_i, 'abstract', ab_pairs_frequency_dict, 'ab') #bad\n",
    "    rare_cpc_dicts, cpc_ideal_match, cpc_full_cover = get_cpc_freq_dicts(meta_i, cpc_frequency_dict)\n",
    "    \n",
    "    rare_ti_dicts, ti_ideal_match, ti_full_cover = get_freq_dicts(meta_i, 'title', ti_frequency_dict, 'ti')\n",
    "    \n",
    "    rare_ab_dicts, ab_ideal_match, ab_full_cover = get_freq_dicts(meta_i, 'abstract', ab_frequency_dict, 'ab')\n",
    "    claims_or_desc_frame = get_claims_and_desc_frame(target, test_meta)\n",
    "    rare_clm_dicts, clm_ideal_match, claims_full_cover = get_freq_dicts(claims_or_desc_frame, 'claims', claims_freqs, 'clm')\n",
    "    rare_desc_dicts, desc_ideal_match, desc_full_cover = get_freq_dicts(claims_or_desc_frame, 'desc', desc_freqs, 'detd')\n",
    "    \n",
    "    st = time.time()\n",
    "\n",
    "    max_len = 0\n",
    "    merged_list = []\n",
    "    for j in meta_i.get_column('publication_number'):\n",
    "        merged_dict = dict()\n",
    "        \n",
    "        for key, value in rare_ti_pair_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            first, second = key.split()\n",
    "            mod_key = (first[3:], second[3:])\n",
    "            query_key = '(' + first + ' ' + second + ')'\n",
    "            if mod_key in ti_pair_ideal_match and (ti_freqs[first[3:]] not in ban_set) and (ti_freqs[second[3:]] not in ban_set):\n",
    "                merged_dict[query_key] = value\n",
    "        \n",
    "        for key, value in rare_ti_ab_pair_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            first, second = key.split()\n",
    "            mod_key = (first[3:], second[3:])\n",
    "            query_key = '(' + first + ' ' + second + ')'\n",
    "            if mod_key in ti_ab_pair_ideal_match and (mod_key[0] not in ban_set) and (mod_key[1] not in ban_set):\n",
    "                merged_dict[query_key] = value\n",
    "                \n",
    "        for key, value in rare_ti_cpc_pair_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            first, second = key.split()\n",
    "            mod_key = (first[3:], second[4:])\n",
    "            query_key = '(' + first + ' ' + second + ')'\n",
    "            #print(rare_ti_cpc_pair_dicts[j])\n",
    "            \n",
    "            if mod_key in ti_cpc_pair_ideal_match and (mod_key[0] not in ban_set) and (mod_key[1] not in ban_set):\n",
    "                merged_dict[query_key] = value        \n",
    "        for key, value in rare_cpc_pair_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            first, second = key.split()\n",
    "            mod_key = (first[4:], second[4:])\n",
    "            query_key = '(' + first + ' ' + second + ')'\n",
    "            if mod_key in cpc_pair_ideal_match:\n",
    "                merged_dict[query_key] = value\n",
    "               \n",
    "        for key, value in rare_ab_cpc_pair_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            first, second = key.split()\n",
    "            mod_key = (first[3:], second[4:])\n",
    "            query_key = '(' + first + ' ' + second + ')'\n",
    "            if mod_key in ab_cpc_pair_ideal_match  and (mod_key[0] not in ban_set):\n",
    "                merged_dict[query_key] = value\n",
    "        for key, value in rare_cpc_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            mod_key = key[4:]\n",
    "            if mod_key in cpc_ideal_match:\n",
    "                merged_dict[key] = value\n",
    "             \n",
    "        for key, value in rare_ti_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            if ' ' in key:\n",
    "                mod_key = key.split('\"')[1]\n",
    "                first, second = mod_key.split()\n",
    "                if not ((ti_freqs[first] not in ban_set) and (ti_freqs[second] not in ban_set)):\n",
    "                    continue\n",
    "            else:\n",
    "                mod_key = key[3:]     \n",
    "            if mod_key in ti_ideal_match and (mod_key not in ban_set):\n",
    "                merged_dict[key] = value\n",
    "                \n",
    "\n",
    "        \n",
    "        for key, value in rare_ab_dicts[j].items():\n",
    "            if value <= 1:\n",
    "                continue\n",
    "            if ' ' in key:\n",
    "                mod_key = key.split('\"')[1]\n",
    "                if mod_key.split()[0] in ban_set or mod_key.split()[1] in ban_set:\n",
    "                    continue\n",
    "            else:\n",
    "                mod_key = key[3:]\n",
    "                if mod_key in ban_set:\n",
    "                    continue\n",
    "                \n",
    "            if mod_key in ab_ideal_match:\n",
    "                merged_dict[key] = value\n",
    "        \n",
    "        for key, value in rare_clm_dicts[j].items():\n",
    "            if value <= 2:\n",
    "                continue\n",
    "            if ' ' in key:\n",
    "                mod_key = key.split('\"')[1]\n",
    "                if mod_key.split()[0] in ban_set or mod_key.split()[1] in ban_set:\n",
    "                    continue\n",
    "            else:\n",
    "                mod_key = key[4:]\n",
    "                if mod_key in ban_set:\n",
    "                    continue\n",
    "                \n",
    "            if mod_key in clm_ideal_match:\n",
    "                merged_dict[key] = value\n",
    "        \n",
    "        for key, value in rare_desc_dicts[j].items():\n",
    "            if value <= 3:\n",
    "                continue\n",
    "            if ' ' in key:\n",
    "                mod_key = key.split('\"')[1]\n",
    "                if mod_key.split()[0] in ban_set or mod_key.split()[1] in ban_set:\n",
    "                    continue\n",
    "            else:\n",
    "                mod_key = key[5:]\n",
    "                if mod_key in ban_set:\n",
    "                    continue\n",
    "                \n",
    "            if mod_key in desc_ideal_match:\n",
    "                merged_dict[key] = value\n",
    "        if len(merged_dict) > max_len:\n",
    "            max_len = len(merged_dict)\n",
    "        merged_list.append(merged_dict)\n",
    "\n",
    "    cleaned_merged_list = []\n",
    "    for d in merged_list:\n",
    "        to_append = list(dict(sorted(d.items(), key=lambda item: item[1], reverse=True)).keys())\n",
    "        cleaned_merged_list.append(to_append)\n",
    "    print(max_len)\n",
    "    \n",
    "    query = ''\n",
    "    \n",
    "    if max_len < 700:\n",
    "        pairs_mscr_list = []\n",
    "        for d in cleaned_merged_list:\n",
    "            new_d = set()\n",
    "            for key1 in d:\n",
    "                for key2 in d:\n",
    "                    if key1 < key2:\n",
    "                        if '\"' in key1 or '\"'  in key2:\n",
    "                            new_d.add((key1, key2))\n",
    "                            continue\n",
    "                        \n",
    "                        if ' ' in key1 and ' ' in key2:\n",
    "                            f1, f2 = key1.split()\n",
    "                            s1, s2 = key2.split()\n",
    "                            if f1 == s1:\n",
    "                                new_d.add((key1, s2 + ')'))\n",
    "                            elif f1[1:] == s2[:-1]:\n",
    "                                new_d.add((key1, s1+ ')'))\n",
    "                            elif f2[:-1] == s1[1:]:\n",
    "                                new_d.add((key1, s2+ ')'))\n",
    "                            elif f2 == s2:\n",
    "                                new_d.add((key1, s1+ ')'))\n",
    "                            else:\n",
    "                                new_d.add((key1, key2))\n",
    "                        \n",
    "                        elif ' ' in key1 and ' ' not in key2:\n",
    "                            \n",
    "                            f1, f2 = key1.split()\n",
    "                            if f1[1:] == key2 or f2[:-1] == key2:\n",
    "                                #continue\n",
    "                                new_d.add((key1, ''))\n",
    "                            else:\n",
    "                                new_d.add((key1, key2))\n",
    "                        elif ' ' in key2 and ' ' not in key1:\n",
    "                            f1, f2 = key2.split()\n",
    "                            if f1[1:] == key1 or f2[:-1] == key1:\n",
    "                                #continue\n",
    "                                new_d.add((key2, ''))\n",
    "                            else:\n",
    "                                new_d.add((key1, key2))\n",
    "                        else:\n",
    "                            new_d.add((key1, key2))\n",
    "                    elif key2 < key1:\n",
    "                        if '\"' in key1 or '\"'  in key2:\n",
    "                            new_d.add((key1, key2))\n",
    "                            continue\n",
    "                        \n",
    "                        if ' ' in key1 and ' ' in key2:\n",
    "                            f1, f2 = key1.split()\n",
    "                            s1, s2 = key2.split()\n",
    "                            if f1 == s1:\n",
    "                                new_d.add((key1, s2 + ')'))\n",
    "                            elif f1[1:] == s2[:-1]:\n",
    "                                new_d.add((key1, s1+ ')'))\n",
    "                            elif f2[:-1] == s1[1:]:\n",
    "                                new_d.add((key1, s2+ ')'))\n",
    "                            elif f2 == s2:\n",
    "                                new_d.add((key1, s1+ ')'))\n",
    "                            else:\n",
    "                                new_d.add((key1, key2))\n",
    "                        \n",
    "                        elif ' ' in key1 and ' ' not in key2:\n",
    "                            \n",
    "                            f1, f2 = key1.split()\n",
    "                            if f1[1:] == key2 or f2[:-1] == key2:\n",
    "                                #continue\n",
    "                                new_d.add((key1, ''))\n",
    "                            else:\n",
    "                                new_d.add((key1, key2))\n",
    "                        elif ' ' in key2 and ' ' not in key1:\n",
    "                            f1, f2 = key2.split()\n",
    "                            if f1[1:] == key1 or f2[:-1] == key1:\n",
    "                                #continue\n",
    "                                new_d.add((key2, ''))\n",
    "                            else:\n",
    "                                new_d.add((key1, key2))\n",
    "                        else:\n",
    "                            new_d.add((key2, key1))\n",
    "            pairs_mscr_list.append(new_d)\n",
    "\n",
    "            \n",
    "        found = 0\n",
    "        min_set = mscr_mod(pairs_mscr_list,0)#mscr_new(cleaned_merged_list,0)\n",
    "        #min_set = list(postprocess(min_set))\n",
    "        min_set = list(min_set)\n",
    "        for el in min_set:\n",
    "            query += '(' + el[0] + ' ' + el[1] + ') OR '\n",
    "            if len(query.split()) > 48:\n",
    "                break\n",
    "        \n",
    "        if len(query.split()) < 48:\n",
    "            if query != '':\n",
    "                if query[-4:] == ' OR ':\n",
    "                    query = query[:-4]\n",
    "            query = '(' + query + ') OR '\n",
    "            \n",
    "        greedy_set = mscr_greedy(pairs_mscr_list, len(query.split()), min_set)\n",
    "        \n",
    "        for el in greedy_set:\n",
    "            query += '(' + el[0] + ' ' + el[1] + ') OR '\n",
    "            if len(query.split()) > 48:\n",
    "                break\n",
    "        \n",
    "            \n",
    "    else:\n",
    "        min_set = mscr_new(cleaned_merged_list, 0)\n",
    "        query += '(' + ' OR '.join(min_set) + ')'\n",
    "        if len(query.split()) < 45:\n",
    "            query = '(' + query + ') OR '\n",
    "            greedy_set = mscr_greedy(cleaned_merged_list, len(query.split()), min_set)\n",
    "            for s in greedy_set:\n",
    "                query += s + ' OR '\n",
    "                if len(query.split()) > 48:\n",
    "                    break\n",
    "\n",
    "    print(query)\n",
    "    \n",
    "    results.append(\n",
    "        {\"publication_number\": test[i, \"publication_number\"], \"query\": query}\n",
    "    )\n",
    "    '''\n",
    "    counter = 0\n",
    "\n",
    "    score=0\n",
    "    start = time.time()\n",
    "    cand = execute_query(query, qp, searcher, target)\n",
    "    print('candidates', len(cand))\n",
    "    \n",
    "    for t in range(50 - len(cand)):\n",
    "        cand.append('null')\n",
    "    print('tokens:', whoosh_utils.count_query_tokens(query))\n",
    "    ap50_score = ap50(cand, target)\n",
    "    inter = count_intersection(cand, target)\n",
    "    print('inter', len(inter))\n",
    "    #print(cand[0])\n",
    "    if ap50_score > score:\n",
    "        score = ap50_score\n",
    "        print('score', score)\n",
    "    scores.append(score)\n",
    "    #print(time.time() - st)\n",
    "    #break'''\n",
    "    \n",
    "#print(\"Average Score:\", sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "883c5194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:22:44.019637Z",
     "iopub.status.busy": "2024-07-24T14:22:44.019138Z",
     "iopub.status.idle": "2024-07-24T14:22:45.299503Z",
     "shell.execute_reply": "2024-07-24T14:22:45.297757Z"
    },
    "papermill": {
     "duration": 1.337092,
     "end_time": "2024-07-24T14:22:45.302407",
     "exception": false,
     "start_time": "2024-07-24T14:22:43.965315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove unwanted files and directories that may cause submission errors\n",
    "!rm -rf /kaggle/working/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3843d1df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T14:22:45.413166Z",
     "iopub.status.busy": "2024-07-24T14:22:45.412542Z",
     "iopub.status.idle": "2024-07-24T14:22:45.446973Z",
     "shell.execute_reply": "2024-07-24T14:22:45.445501Z"
    },
    "papermill": {
     "duration": 0.094294,
     "end_time": "2024-07-24T14:22:45.449562",
     "exception": false,
     "start_time": "2024-07-24T14:22:45.355268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>publication_number</th><th>query</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;US-2017082634-A1&quot;</td><td>&quot;((ab:spectrometry ab:&quot;mass spe…</td></tr><tr><td>&quot;US-2017180470-A1&quot;</td><td>&quot;((detd:&quot;computing device&quot; detd…</td></tr><tr><td>&quot;US-2018029544-A1&quot;</td><td>&quot;((cpc:Y02E10/50 OR ti:battery …</td></tr><tr><td>&quot;US-2022408153-A1&quot;</td><td>&quot;((detd:family OR detd:&quot;informa…</td></tr><tr><td>&quot;US-2268569-A&quot;</td><td>&quot;(cpc:E02F3/3486 cpc:E02F9/022)…</td></tr><tr><td>&quot;US-3371854-A&quot;</td><td>&quot;(ti:vacuum ti:&quot;vacuum pump&quot;) O…</td></tr><tr><td>&quot;US-3589189-A&quot;</td><td>&quot;((ti:meter cpc:G01F3/18) ) OR …</td></tr><tr><td>&quot;US-3881203-A&quot;</td><td>&quot;(detd:rounded ti:paper) OR ((t…</td></tr><tr><td>&quot;US-4845770-A&quot;</td><td>&quot;(((ti:reader ab:reader) ) OR (…</td></tr><tr><td>&quot;US-695233-A&quot;</td><td>&quot;((ti:acetylene ti:&quot;acetylene g…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌────────────────────┬─────────────────────────────────┐\n",
       "│ publication_number ┆ query                           │\n",
       "│ ---                ┆ ---                             │\n",
       "│ str                ┆ str                             │\n",
       "╞════════════════════╪═════════════════════════════════╡\n",
       "│ US-2017082634-A1   ┆ ((ab:spectrometry ab:\"mass spe… │\n",
       "│ US-2017180470-A1   ┆ ((detd:\"computing device\" detd… │\n",
       "│ US-2018029544-A1   ┆ ((cpc:Y02E10/50 OR ti:battery … │\n",
       "│ US-2022408153-A1   ┆ ((detd:family OR detd:\"informa… │\n",
       "│ US-2268569-A       ┆ (cpc:E02F3/3486 cpc:E02F9/022)… │\n",
       "│ US-3371854-A       ┆ (ti:vacuum ti:\"vacuum pump\") O… │\n",
       "│ US-3589189-A       ┆ ((ti:meter cpc:G01F3/18) ) OR … │\n",
       "│ US-3881203-A       ┆ (detd:rounded ti:paper) OR ((t… │\n",
       "│ US-4845770-A       ┆ (((ti:reader ab:reader) ) OR (… │\n",
       "│ US-695233-A        ┆ ((ti:acetylene ti:\"acetylene g… │\n",
       "└────────────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pl.DataFrame(results)\n",
    "submission.write_csv(\"submission.csv\")\n",
    "\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8060720,
     "sourceId": 59575,
     "sourceType": "competition"
    },
    {
     "datasetId": 4892374,
     "sourceId": 8246447,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5007812,
     "sourceId": 8413600,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4517815,
     "sourceId": 8479599,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5423759,
     "sourceId": 9004494,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 174185912,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187661035,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187661170,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187688749,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187688793,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187688850,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187688916,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187697593,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187697707,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187697878,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187709099,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187709218,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 188212699,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 188212850,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 188509942,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1469.048653,
   "end_time": "2024-07-24T14:22:46.437413",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-24T13:58:17.388760",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
